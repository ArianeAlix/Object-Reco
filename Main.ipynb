{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird image classification\n",
    "### Ariane ALIX\n",
    "### 26/11/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experimenting simple models and ideas\n",
    "### 1.1 Initial model (given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "%run main.py --epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1082 (0%)]\tLoss: 2.989828\n",
      "Train Epoch: 1 [640/1082 (59%)]\tLoss: 3.007554\n",
      "\n",
      "Validation set: Average loss: 0.0580, Accuracy: 5/103 (5%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/1082 (0%)]\tLoss: 2.981745\n",
      "Train Epoch: 2 [640/1082 (59%)]\tLoss: 2.971583\n",
      "\n",
      "Validation set: Average loss: 0.0573, Accuracy: 4/103 (4%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/1082 (0%)]\tLoss: 2.942628\n",
      "Train Epoch: 3 [640/1082 (59%)]\tLoss: 2.830668\n",
      "\n",
      "Validation set: Average loss: 0.0543, Accuracy: 17/103 (17%)\n",
      "Saved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 4 [0/1082 (0%)]\tLoss: 2.789883\n",
      "Train Epoch: 4 [640/1082 (59%)]\tLoss: 2.713978\n",
      "\n",
      "Validation set: Average loss: 0.0517, Accuracy: 13/103 (13%)\n",
      "Saved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 5 [0/1082 (0%)]\tLoss: 2.656481\n",
      "Train Epoch: 5 [640/1082 (59%)]\tLoss: 2.679133\n",
      "\n",
      "Validation set: Average loss: 0.0518, Accuracy: 18/103 (17%)\n",
      "Saved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 6 [0/1082 (0%)]\tLoss: 2.668342\n",
      "Train Epoch: 6 [640/1082 (59%)]\tLoss: 2.736262\n",
      "\n",
      "Validation set: Average loss: 0.0577, Accuracy: 9/103 (9%)\n",
      "Saved model to experiment/model_6.pth. You can run `python evaluate.py --model experiment/model_6.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 7 [0/1082 (0%)]\tLoss: 2.828056\n",
      "Train Epoch: 7 [640/1082 (59%)]\tLoss: 2.382013\n",
      "\n",
      "Validation set: Average loss: 0.0492, Accuracy: 28/103 (27%)\n",
      "Saved model to experiment/model_7.pth. You can run `python evaluate.py --model experiment/model_7.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 8 [0/1082 (0%)]\tLoss: 2.467760\n",
      "Train Epoch: 8 [640/1082 (59%)]\tLoss: 2.274601\n",
      "\n",
      "Validation set: Average loss: 0.0474, Accuracy: 28/103 (27%)\n",
      "Saved model to experiment/model_8.pth. You can run `python evaluate.py --model experiment/model_8.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 9 [0/1082 (0%)]\tLoss: 2.554936\n",
      "Train Epoch: 9 [640/1082 (59%)]\tLoss: 2.372739\n",
      "\n",
      "Validation set: Average loss: 0.0448, Accuracy: 32/103 (31%)\n",
      "Saved model to experiment/model_9.pth. You can run `python evaluate.py --model experiment/model_9.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 10 [0/1082 (0%)]\tLoss: 2.076187\n",
      "Train Epoch: 10 [640/1082 (59%)]\tLoss: 2.405241\n",
      "\n",
      "Validation set: Average loss: 0.0529, Accuracy: 14/103 (14%)\n",
      "Saved model to experiment/model_10.pth. You can run `python evaluate.py --model experiment/model_10.pth` to generate the Kaggle formatted csv file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 New model based on animal (faces) recognition paper > Net2\n",
    "\n",
    "https://www.researchgate.net/publication/320162958_Animal_Recognition_System_Based_on_Convolutional_Neural_Network\n",
    "\n",
    "It is interesting because the original version was made to look at faces of animals (with some quite similar, like foxes and wolves) which have patterns of hair like birds with their feathers; moreover, the size of the filters were kept because their picture were 2 times less wide (32x32), but were approximately twice as zoomed on the zone of interest.\n",
    "\n",
    "Another interseting fact is the use of a dropout : it drops out outputs with a probability of 0.1 to avoid overfitting (it was 0.25 in their case but they has fewer classes, and we don't want to lose to much of one class if we are not lucky).\n",
    "\n",
    "We also added padding and changed the number of classes and final neurons in the last layers to stay proportionnal, and deleted the softmax at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "%run main.py --epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2164 (0%)]\tLoss: 3.009687\n",
      "Train Epoch: 1 [640/2164 (29%)]\tLoss: 2.938819\n",
      "Train Epoch: 1 [1280/2164 (59%)]\tLoss: 2.941729\n",
      "Train Epoch: 1 [1920/2164 (88%)]\tLoss: 2.958346\n",
      "\n",
      "Validation set: Average loss: 0.0553, Accuracy: 12/103 (12%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/2164 (0%)]\tLoss: 2.730878\n",
      "Train Epoch: 2 [640/2164 (29%)]\tLoss: 2.781794\n",
      "Train Epoch: 2 [1280/2164 (59%)]\tLoss: 2.799252\n",
      "Train Epoch: 2 [1920/2164 (88%)]\tLoss: 2.523937\n",
      "\n",
      "Validation set: Average loss: 0.0534, Accuracy: 18/103 (17%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/2164 (0%)]\tLoss: 2.781735\n",
      "Train Epoch: 3 [640/2164 (29%)]\tLoss: 2.570157\n",
      "Train Epoch: 3 [1280/2164 (59%)]\tLoss: 2.625766\n",
      "Train Epoch: 3 [1920/2164 (88%)]\tLoss: 2.545475\n",
      "\n",
      "Validation set: Average loss: 0.0478, Accuracy: 23/103 (22%)\n",
      "Saved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 4 [0/2164 (0%)]\tLoss: 2.403578\n",
      "Train Epoch: 4 [640/2164 (29%)]\tLoss: 2.294352\n",
      "Train Epoch: 4 [1280/2164 (59%)]\tLoss: 2.588709\n",
      "Train Epoch: 4 [1920/2164 (88%)]\tLoss: 2.157878\n",
      "\n",
      "Validation set: Average loss: 0.0444, Accuracy: 29/103 (28%)\n",
      "Saved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 5 [0/2164 (0%)]\tLoss: 1.960432\n",
      "Train Epoch: 5 [640/2164 (29%)]\tLoss: 2.424082\n",
      "Train Epoch: 5 [1280/2164 (59%)]\tLoss: 2.403861\n",
      "Train Epoch: 5 [1920/2164 (88%)]\tLoss: 2.142887\n",
      "\n",
      "Validation set: Average loss: 0.0472, Accuracy: 24/103 (23%)\n",
      "Saved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 6 [0/2164 (0%)]\tLoss: 2.340170\n",
      "Train Epoch: 6 [640/2164 (29%)]\tLoss: 1.973539\n",
      "Train Epoch: 6 [1280/2164 (59%)]\tLoss: 2.424167\n",
      "Train Epoch: 6 [1920/2164 (88%)]\tLoss: 2.375806\n",
      "\n",
      "Validation set: Average loss: 0.0432, Accuracy: 27/103 (26%)\n",
      "Saved model to experiment/model_6.pth. You can run `python evaluate.py --model experiment/model_6.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 7 [0/2164 (0%)]\tLoss: 1.768076\n",
      "Train Epoch: 7 [640/2164 (29%)]\tLoss: 1.987283\n",
      "Train Epoch: 7 [1280/2164 (59%)]\tLoss: 1.712073\n",
      "Train Epoch: 7 [1920/2164 (88%)]\tLoss: 2.268031\n",
      "\n",
      "Validation set: Average loss: 0.0433, Accuracy: 29/103 (28%)\n",
      "Saved model to experiment/model_7.pth. You can run `python evaluate.py --model experiment/model_7.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 8 [0/2164 (0%)]\tLoss: 2.010490\n",
      "Train Epoch: 8 [640/2164 (29%)]\tLoss: 2.136492\n",
      "Train Epoch: 8 [1280/2164 (59%)]\tLoss: 1.754956\n",
      "Train Epoch: 8 [1920/2164 (88%)]\tLoss: 2.050238\n",
      "\n",
      "Validation set: Average loss: 0.0441, Accuracy: 28/103 (27%)\n",
      "Saved model to experiment/model_8.pth. You can run `python evaluate.py --model experiment/model_8.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 9 [0/2164 (0%)]\tLoss: 2.037308\n",
      "Train Epoch: 9 [640/2164 (29%)]\tLoss: 1.816029\n",
      "Train Epoch: 9 [1280/2164 (59%)]\tLoss: 2.190270\n",
      "Train Epoch: 9 [1920/2164 (88%)]\tLoss: 2.062086\n",
      "\n",
      "Validation set: Average loss: 0.0462, Accuracy: 29/103 (28%)\n",
      "Saved model to experiment/model_9.pth. You can run `python evaluate.py --model experiment/model_9.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 10 [0/2164 (0%)]\tLoss: 1.842540\n",
      "Train Epoch: 10 [640/2164 (29%)]\tLoss: 1.719081\n",
      "Train Epoch: 10 [1280/2164 (59%)]\tLoss: 2.013179\n",
      "Train Epoch: 10 [1920/2164 (88%)]\tLoss: 1.614093\n",
      "\n",
      "Validation set: Average loss: 0.0458, Accuracy: 34/103 (33%)\n",
      "Saved model to experiment/model_10.pth. You can run `python evaluate.py --model experiment/model_10.pth` to generate the Kaggle formatted csv file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_**\n",
    "We see better results, still not that good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 CPU vs local GPU\n",
    "\n",
    "*main.py* has been modified to choose as args if we want to use the CPU or GPU. We test the two on 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Train Epoch: 1 [0/2164 (0%)]\tLoss: 3.003148\n",
      "Train Epoch: 1 [640/2164 (29%)]\tLoss: 2.972824\n",
      "Train Epoch: 1 [1280/2164 (59%)]\tLoss: 2.909789\n",
      "Train Epoch: 1 [1920/2164 (88%)]\tLoss: 2.981264\n",
      "\n",
      "Validation set: Average loss: 0.0566, Accuracy: 7/103 (7%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/2164 (0%)]\tLoss: 2.835259\n",
      "Train Epoch: 2 [640/2164 (29%)]\tLoss: 2.937826\n",
      "Train Epoch: 2 [1280/2164 (59%)]\tLoss: 2.675451\n",
      "Train Epoch: 2 [1920/2164 (88%)]\tLoss: 2.812554\n",
      "\n",
      "Validation set: Average loss: 0.0512, Accuracy: 13/103 (13%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/2164 (0%)]\tLoss: 2.756968\n",
      "Train Epoch: 3 [640/2164 (29%)]\tLoss: 2.582169\n",
      "Train Epoch: 3 [1280/2164 (59%)]\tLoss: 2.540673\n",
      "Train Epoch: 3 [1920/2164 (88%)]\tLoss: 2.567905\n",
      "\n",
      "Validation set: Average loss: 0.0510, Accuracy: 20/103 (19%)\n",
      "Saved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 4 [0/2164 (0%)]\tLoss: 2.424804\n",
      "Train Epoch: 4 [640/2164 (29%)]\tLoss: 2.695248\n",
      "Train Epoch: 4 [1280/2164 (59%)]\tLoss: 2.467574\n",
      "Train Epoch: 4 [1920/2164 (88%)]\tLoss: 2.467476\n",
      "\n",
      "Validation set: Average loss: 0.0453, Accuracy: 29/103 (28%)\n",
      "Saved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 5 [0/2164 (0%)]\tLoss: 2.393374\n",
      "Train Epoch: 5 [640/2164 (29%)]\tLoss: 2.280413\n",
      "Train Epoch: 5 [1280/2164 (59%)]\tLoss: 2.252582\n",
      "Train Epoch: 5 [1920/2164 (88%)]\tLoss: 2.356467\n",
      "\n",
      "Validation set: Average loss: 0.0423, Accuracy: 31/103 (30%)\n",
      "Saved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "CPU- Time of execution : 195.77610898017883 s\n",
      "Using CPU\n",
      "Train Epoch: 1 [0/2164 (0%)]\tLoss: 3.003148\n",
      "Train Epoch: 1 [640/2164 (29%)]\tLoss: 2.972824\n",
      "Train Epoch: 1 [1280/2164 (59%)]\tLoss: 2.909789\n",
      "Train Epoch: 1 [1920/2164 (88%)]\tLoss: 2.981264\n",
      "\n",
      "Validation set: Average loss: 0.0566, Accuracy: 7/103 (7%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/2164 (0%)]\tLoss: 2.835259\n",
      "Train Epoch: 2 [640/2164 (29%)]\tLoss: 2.937826\n",
      "Train Epoch: 2 [1280/2164 (59%)]\tLoss: 2.675451\n",
      "Train Epoch: 2 [1920/2164 (88%)]\tLoss: 2.812554\n",
      "\n",
      "Validation set: Average loss: 0.0512, Accuracy: 13/103 (13%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/2164 (0%)]\tLoss: 2.756968\n",
      "Train Epoch: 3 [640/2164 (29%)]\tLoss: 2.582169\n",
      "Train Epoch: 3 [1280/2164 (59%)]\tLoss: 2.540673\n",
      "Train Epoch: 3 [1920/2164 (88%)]\tLoss: 2.567905\n",
      "\n",
      "Validation set: Average loss: 0.0510, Accuracy: 20/103 (19%)\n",
      "Saved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 4 [0/2164 (0%)]\tLoss: 2.424804\n",
      "Train Epoch: 4 [640/2164 (29%)]\tLoss: 2.695248\n",
      "Train Epoch: 4 [1280/2164 (59%)]\tLoss: 2.467574\n",
      "Train Epoch: 4 [1920/2164 (88%)]\tLoss: 2.467476\n",
      "\n",
      "Validation set: Average loss: 0.0453, Accuracy: 29/103 (28%)\n",
      "Saved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 5 [0/2164 (0%)]\tLoss: 2.393374\n",
      "Train Epoch: 5 [640/2164 (29%)]\tLoss: 2.280413\n",
      "Train Epoch: 5 [1280/2164 (59%)]\tLoss: 2.252582\n",
      "Train Epoch: 5 [1920/2164 (88%)]\tLoss: 2.356467\n",
      "\n",
      "Validation set: Average loss: 0.0423, Accuracy: 31/103 (30%)\n",
      "Saved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "CPU- Time of execution : 198.10046291351318 s\n"
     ]
    }
   ],
   "source": [
    "### CPU\n",
    "start=time.time()\n",
    "\n",
    "%run main.py --epochs=5 --cgpu='CPU'\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
    "\n",
    "print('CPU- Time of execution :',time.time()-start,'s')    \n",
    "    \n",
    "    \n",
    "### GPU \n",
    "start=time.time()\n",
    "\n",
    "%run main.py --epochs=5 --cgpu='GPU'    \n",
    "    \n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
    "    \n",
    "print('GPU- Time of execution :',time.time()-start,'s') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_**\n",
    "Almost the same time. We will keep using the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using pre-trained models\n",
    "### 2.1 Testing ResNet34 without any modification except changing the last layer \n",
    "So that it matches our case (20 classes). (Still using the expanded dataset with random modifications). We let all the layers free to evolve so we can fintune all the parameters of the net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Look for good learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d90995d98f54fdb8d60fc5726b9e0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "%run main.py --epochs=10 --cgpu='CPU'\n",
    "\n",
    "#training dataset\n",
    "training_set = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms), batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "\n",
    "#Model\n",
    "model = torchvision.models.resnet34(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 20)\n",
    "#model.load_state_dict(torch.load('experiment/model_saved_res152.pth'))\n",
    "\n",
    "#Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=args.momentum)\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion)\n",
    "lr_finder.range_test(train_loader=training_set,val_loader=None, end_lr=100, num_iter=100)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest lost is : 2.31264224103441 reached for LR = 0.11220184543019632\n"
     ]
    }
   ],
   "source": [
    "lrs = lr_finder.history[\"lr\"]#avoid the first small values\n",
    "losses = lr_finder.history[\"loss\"]\n",
    "\n",
    "\n",
    "print('The smallest lost is :',np.min(losses),'reached for LR =',lrs[np.argmin(losses)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Trying the ResNet34 with a 0.11 learning rate (found above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Train Epoch: 1 [0/1082 (0%)]\tLoss: 3.519068\n",
      "Train Epoch: 1 [640/1082 (59%)]\tLoss: 3.413718\n",
      "\n",
      "Validation set: Average loss: 6.0332, Accuracy: 7/103 (7%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/1082 (0%)]\tLoss: 2.925918\n",
      "Train Epoch: 2 [640/1082 (59%)]\tLoss: 2.799205\n",
      "\n",
      "Validation set: Average loss: 0.0518, Accuracy: 14/103 (14%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/1082 (0%)]\tLoss: 2.726650\n",
      "Train Epoch: 3 [640/1082 (59%)]\tLoss: 2.678522\n",
      "\n",
      "Validation set: Average loss: 0.0519, Accuracy: 17/103 (17%)\n",
      "Saved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 4 [0/1082 (0%)]\tLoss: 2.507774\n",
      "Train Epoch: 4 [640/1082 (59%)]\tLoss: 2.305955\n",
      "\n",
      "Validation set: Average loss: 0.0447, Accuracy: 22/103 (21%)\n",
      "Saved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 5 [0/1082 (0%)]\tLoss: 2.065471\n",
      "Train Epoch: 5 [640/1082 (59%)]\tLoss: 2.181704\n",
      "\n",
      "Validation set: Average loss: 0.0457, Accuracy: 35/103 (34%)\n",
      "Saved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 6 [0/1082 (0%)]\tLoss: 1.516092\n",
      "Train Epoch: 6 [640/1082 (59%)]\tLoss: 1.657050\n",
      "\n",
      "Validation set: Average loss: 0.0465, Accuracy: 32/103 (31%)\n",
      "Saved model to experiment/model_6.pth. You can run `python evaluate.py --model experiment/model_6.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 7 [0/1082 (0%)]\tLoss: 1.514611\n",
      "Train Epoch: 7 [640/1082 (59%)]\tLoss: 1.373572\n",
      "\n",
      "Validation set: Average loss: 0.0399, Accuracy: 41/103 (40%)\n",
      "Saved model to experiment/model_7.pth. You can run `python evaluate.py --model experiment/model_7.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 8 [0/1082 (0%)]\tLoss: 1.066330\n",
      "Train Epoch: 8 [640/1082 (59%)]\tLoss: 1.095245\n",
      "\n",
      "Validation set: Average loss: 0.0547, Accuracy: 27/103 (26%)\n",
      "Saved model to experiment/model_8.pth. You can run `python evaluate.py --model experiment/model_8.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 9 [0/1082 (0%)]\tLoss: 0.953135\n",
      "Train Epoch: 9 [640/1082 (59%)]\tLoss: 1.786842\n",
      "\n",
      "Validation set: Average loss: 0.0452, Accuracy: 40/103 (39%)\n",
      "Saved model to experiment/model_9.pth. You can run `python evaluate.py --model experiment/model_9.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 10 [0/1082 (0%)]\tLoss: 0.874453\n",
      "Train Epoch: 10 [640/1082 (59%)]\tLoss: 1.363203\n",
      "\n",
      "Validation set: Average loss: 0.0520, Accuracy: 45/103 (44%)\n",
      "Saved model to experiment/model_10.pth. You can run `python evaluate.py --model experiment/model_10.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "CPU- Time of execution : 818.7175388336182 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "%run main.py --epochs=10 --cgpu='CPU' --lr=0.11\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
    "\n",
    "print('CPU- Time of execution :',time.time()-start,'s')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Keeping the best training and looking again for the best LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe4ec9fbf8c4812a34e0160c2a84fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "#training dataset\n",
    "training_set = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms), batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "#Model\n",
    "model = torchvision.models.resnet34(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 20)\n",
    "model.load_state_dict(torch.load('experiment/model_res34_step1.pth'))\n",
    "\n",
    "#Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=args.momentum)\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion)\n",
    "lr_finder.range_test(train_loader=training_set,val_loader=None, end_lr=100, num_iter=100)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest lost is : 0.44053973368943405 reached for LR = 0.14125375446227542\n"
     ]
    }
   ],
   "source": [
    "lrs = lr_finder.history[\"lr\"]#avoid the first small values\n",
    "losses = lr_finder.history[\"loss\"]\n",
    "\n",
    "print('The smallest lost is :',np.min(losses),'reached for LR =',lrs[np.argmin(losses)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4  Relaunching the ResNet34 from the best training saved with a 0.11 learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Train Epoch: 1 [0/1082 (0%)]\tLoss: 0.690365\n",
      "Train Epoch: 1 [640/1082 (59%)]\tLoss: 0.960003\n",
      "\\Training set: ccuracy: 801/1082\n",
      "\n",
      "Validation set: Average loss: 0.0605, Accuracy: 45/103 (44%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/1082 (0%)]\tLoss: 0.753638\n",
      "Train Epoch: 2 [640/1082 (59%)]\tLoss: 0.531909\n",
      "\\Training set: ccuracy: 807/1082\n",
      "\n",
      "Validation set: Average loss: 0.0575, Accuracy: 36/103 (35%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/1082 (0%)]\tLoss: 0.591375\n",
      "Train Epoch: 3 [640/1082 (59%)]\tLoss: 0.299660\n",
      "\\Training set: ccuracy: 922/1082\n",
      "\n",
      "Validation set: Average loss: 0.0498, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 4 [0/1082 (0%)]\tLoss: 0.179397\n",
      "Train Epoch: 4 [640/1082 (59%)]\tLoss: 0.656621\n",
      "\\Training set: ccuracy: 900/1082\n",
      "\n",
      "Validation set: Average loss: 0.0873, Accuracy: 11/103 (11%)\n",
      "Saved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 5 [0/1082 (0%)]\tLoss: 0.810789\n",
      "Train Epoch: 5 [640/1082 (59%)]\tLoss: 0.540746\n",
      "\\Training set: ccuracy: 837/1082\n",
      "\n",
      "Validation set: Average loss: 0.0665, Accuracy: 33/103 (32%)\n",
      "Saved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 6 [0/1082 (0%)]\tLoss: 0.452974\n",
      "Train Epoch: 6 [640/1082 (59%)]\tLoss: 0.189057\n",
      "\\Training set: ccuracy: 974/1082\n",
      "\n",
      "Validation set: Average loss: 0.0573, Accuracy: 44/103 (43%)\n",
      "Saved model to experiment/model_6.pth. You can run `python evaluate.py --model experiment/model_6.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 7 [0/1082 (0%)]\tLoss: 0.078203\n",
      "Train Epoch: 7 [640/1082 (59%)]\tLoss: 0.174537\n",
      "\\Training set: ccuracy: 1047/1082\n",
      "\n",
      "Validation set: Average loss: 0.0614, Accuracy: 46/103 (45%)\n",
      "Saved model to experiment/model_7.pth. You can run `python evaluate.py --model experiment/model_7.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 8 [0/1082 (0%)]\tLoss: 0.022700\n",
      "Train Epoch: 8 [640/1082 (59%)]\tLoss: 0.062553\n",
      "\\Training set: ccuracy: 1062/1082\n",
      "\n",
      "Validation set: Average loss: 0.0609, Accuracy: 44/103 (43%)\n",
      "Saved model to experiment/model_8.pth. You can run `python evaluate.py --model experiment/model_8.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 9 [0/1082 (0%)]\tLoss: 0.010092\n",
      "Train Epoch: 9 [640/1082 (59%)]\tLoss: 0.160222\n",
      "\\Training set: ccuracy: 1052/1082\n",
      "\n",
      "Validation set: Average loss: 0.0805, Accuracy: 39/103 (38%)\n",
      "Saved model to experiment/model_9.pth. You can run `python evaluate.py --model experiment/model_9.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 10 [0/1082 (0%)]\tLoss: 0.026276\n",
      "Train Epoch: 10 [640/1082 (59%)]\tLoss: 0.038755\n",
      "\\Training set: ccuracy: 1067/1082\n",
      "\n",
      "Validation set: Average loss: 0.0669, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_10.pth. You can run `python evaluate.py --model experiment/model_10.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 11 [0/1082 (0%)]\tLoss: 0.020678\n",
      "Train Epoch: 11 [640/1082 (59%)]\tLoss: 0.074795\n",
      "\\Training set: ccuracy: 1064/1082\n",
      "\n",
      "Validation set: Average loss: 0.0625, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_11.pth. You can run `python evaluate.py --model experiment/model_11.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 12 [0/1082 (0%)]\tLoss: 0.017209\n",
      "Train Epoch: 12 [640/1082 (59%)]\tLoss: 0.243959\n",
      "\\Training set: ccuracy: 1064/1082\n",
      "\n",
      "Validation set: Average loss: 0.0669, Accuracy: 41/103 (40%)\n",
      "Saved model to experiment/model_12.pth. You can run `python evaluate.py --model experiment/model_12.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 13 [0/1082 (0%)]\tLoss: 0.031053\n",
      "Train Epoch: 13 [640/1082 (59%)]\tLoss: 0.010792\n",
      "\\Training set: ccuracy: 1062/1082\n",
      "\n",
      "Validation set: Average loss: 0.0718, Accuracy: 40/103 (39%)\n",
      "Saved model to experiment/model_13.pth. You can run `python evaluate.py --model experiment/model_13.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 14 [0/1082 (0%)]\tLoss: 0.195798\n",
      "Train Epoch: 14 [640/1082 (59%)]\tLoss: 0.192683\n",
      "\\Training set: ccuracy: 1046/1082\n",
      "\n",
      "Validation set: Average loss: 0.0867, Accuracy: 39/103 (38%)\n",
      "Saved model to experiment/model_14.pth. You can run `python evaluate.py --model experiment/model_14.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 15 [0/1082 (0%)]\tLoss: 0.134289\n",
      "Train Epoch: 15 [640/1082 (59%)]\tLoss: 0.136380\n",
      "\\Training set: ccuracy: 1039/1082\n",
      "\n",
      "Validation set: Average loss: 0.0648, Accuracy: 44/103 (43%)\n",
      "Saved model to experiment/model_15.pth. You can run `python evaluate.py --model experiment/model_15.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 16 [0/1082 (0%)]\tLoss: 0.041596\n",
      "Train Epoch: 16 [640/1082 (59%)]\tLoss: 0.086557\n",
      "\\Training set: ccuracy: 1062/1082\n",
      "\n",
      "Validation set: Average loss: 0.0604, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_16.pth. You can run `python evaluate.py --model experiment/model_16.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 17 [0/1082 (0%)]\tLoss: 0.073077\n",
      "Train Epoch: 17 [640/1082 (59%)]\tLoss: 0.039339\n",
      "\\Training set: ccuracy: 1047/1082\n",
      "\n",
      "Validation set: Average loss: 0.0689, Accuracy: 41/103 (40%)\n",
      "Saved model to experiment/model_17.pth. You can run `python evaluate.py --model experiment/model_17.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 18 [0/1082 (0%)]\tLoss: 0.084622\n",
      "Train Epoch: 18 [640/1082 (59%)]\tLoss: 0.025142\n",
      "\\Training set: ccuracy: 1057/1082\n",
      "\n",
      "Validation set: Average loss: 0.0655, Accuracy: 45/103 (44%)\n",
      "Saved model to experiment/model_18.pth. You can run `python evaluate.py --model experiment/model_18.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 19 [0/1082 (0%)]\tLoss: 0.004786\n",
      "Train Epoch: 19 [640/1082 (59%)]\tLoss: 0.016190\n",
      "\\Training set: ccuracy: 1072/1082\n",
      "\n",
      "Validation set: Average loss: 0.0557, Accuracy: 49/103 (48%)\n",
      "Saved model to experiment/model_19.pth. You can run `python evaluate.py --model experiment/model_19.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 20 [0/1082 (0%)]\tLoss: 0.014221\n",
      "Train Epoch: 20 [640/1082 (59%)]\tLoss: 0.004273\n",
      "\\Training set: ccuracy: 1081/1082\n",
      "\n",
      "Validation set: Average loss: 0.0595, Accuracy: 49/103 (48%)\n",
      "Saved model to experiment/model_20.pth. You can run `python evaluate.py --model experiment/model_20.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 21 [0/1082 (0%)]\tLoss: 0.003539\n",
      "Train Epoch: 21 [640/1082 (59%)]\tLoss: 0.001497\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0635, Accuracy: 50/103 (49%)\n",
      "Saved model to experiment/model_21.pth. You can run `python evaluate.py --model experiment/model_21.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 22 [0/1082 (0%)]\tLoss: 0.001204\n",
      "Train Epoch: 22 [640/1082 (59%)]\tLoss: 0.001427\n",
      "\\Training set: ccuracy: 1081/1082\n",
      "\n",
      "Validation set: Average loss: 0.0609, Accuracy: 50/103 (49%)\n",
      "Saved model to experiment/model_22.pth. You can run `python evaluate.py --model experiment/model_22.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 23 [0/1082 (0%)]\tLoss: 0.000849\n",
      "Train Epoch: 23 [640/1082 (59%)]\tLoss: 0.001418\n",
      "\\Training set: ccuracy: 1081/1082\n",
      "\n",
      "Validation set: Average loss: 0.0642, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_23.pth. You can run `python evaluate.py --model experiment/model_23.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 24 [0/1082 (0%)]\tLoss: 0.001782\n",
      "Train Epoch: 24 [640/1082 (59%)]\tLoss: 0.000455\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0646, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_24.pth. You can run `python evaluate.py --model experiment/model_24.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 25 [0/1082 (0%)]\tLoss: 0.000424\n",
      "Train Epoch: 25 [640/1082 (59%)]\tLoss: 0.000450\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0647, Accuracy: 46/103 (45%)\n",
      "Saved model to experiment/model_25.pth. You can run `python evaluate.py --model experiment/model_25.pth` to generate the Kaggle formatted csv file\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [0/1082 (0%)]\tLoss: 0.000916\n",
      "Train Epoch: 26 [640/1082 (59%)]\tLoss: 0.000406\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0661, Accuracy: 49/103 (48%)\n",
      "Saved model to experiment/model_26.pth. You can run `python evaluate.py --model experiment/model_26.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 27 [0/1082 (0%)]\tLoss: 0.000771\n",
      "Train Epoch: 27 [640/1082 (59%)]\tLoss: 0.000280\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0652, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_27.pth. You can run `python evaluate.py --model experiment/model_27.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 28 [0/1082 (0%)]\tLoss: 0.000933\n",
      "Train Epoch: 28 [640/1082 (59%)]\tLoss: 0.000165\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0665, Accuracy: 50/103 (49%)\n",
      "Saved model to experiment/model_28.pth. You can run `python evaluate.py --model experiment/model_28.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 29 [0/1082 (0%)]\tLoss: 0.000200\n",
      "Train Epoch: 29 [640/1082 (59%)]\tLoss: 0.001240\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0659, Accuracy: 49/103 (48%)\n",
      "Saved model to experiment/model_29.pth. You can run `python evaluate.py --model experiment/model_29.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 30 [0/1082 (0%)]\tLoss: 0.000381\n",
      "Train Epoch: 30 [640/1082 (59%)]\tLoss: 0.000714\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0670, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_30.pth. You can run `python evaluate.py --model experiment/model_30.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 31 [0/1082 (0%)]\tLoss: 0.001525\n",
      "Train Epoch: 31 [640/1082 (59%)]\tLoss: 0.001272\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0676, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_31.pth. You can run `python evaluate.py --model experiment/model_31.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 32 [0/1082 (0%)]\tLoss: 0.000480\n",
      "Train Epoch: 32 [640/1082 (59%)]\tLoss: 0.000190\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0678, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_32.pth. You can run `python evaluate.py --model experiment/model_32.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 33 [0/1082 (0%)]\tLoss: 0.000731\n",
      "Train Epoch: 33 [640/1082 (59%)]\tLoss: 0.000194\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0698, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_33.pth. You can run `python evaluate.py --model experiment/model_33.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 34 [0/1082 (0%)]\tLoss: 0.000109\n",
      "Train Epoch: 34 [640/1082 (59%)]\tLoss: 0.000991\n",
      "\\Training set: ccuracy: 1080/1082\n",
      "\n",
      "Validation set: Average loss: 0.0687, Accuracy: 49/103 (48%)\n",
      "Saved model to experiment/model_34.pth. You can run `python evaluate.py --model experiment/model_34.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 35 [0/1082 (0%)]\tLoss: 0.009157\n",
      "Train Epoch: 35 [640/1082 (59%)]\tLoss: 0.013468\n",
      "\\Training set: ccuracy: 1079/1082\n",
      "\n",
      "Validation set: Average loss: 0.0683, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_35.pth. You can run `python evaluate.py --model experiment/model_35.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 36 [0/1082 (0%)]\tLoss: 0.002771\n",
      "Train Epoch: 36 [640/1082 (59%)]\tLoss: 0.000767\n",
      "\\Training set: ccuracy: 1081/1082\n",
      "\n",
      "Validation set: Average loss: 0.0659, Accuracy: 49/103 (48%)\n",
      "Saved model to experiment/model_36.pth. You can run `python evaluate.py --model experiment/model_36.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 37 [0/1082 (0%)]\tLoss: 0.000490\n",
      "Train Epoch: 37 [640/1082 (59%)]\tLoss: 0.000354\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0684, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_37.pth. You can run `python evaluate.py --model experiment/model_37.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 38 [0/1082 (0%)]\tLoss: 0.000409\n",
      "Train Epoch: 38 [640/1082 (59%)]\tLoss: 0.000223\n",
      "\\Training set: ccuracy: 1081/1082\n",
      "\n",
      "Validation set: Average loss: 0.0678, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_38.pth. You can run `python evaluate.py --model experiment/model_38.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 39 [0/1082 (0%)]\tLoss: 0.000476\n",
      "Train Epoch: 39 [640/1082 (59%)]\tLoss: 0.000418\n",
      "\\Training set: ccuracy: 1081/1082\n",
      "\n",
      "Validation set: Average loss: 0.0690, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_39.pth. You can run `python evaluate.py --model experiment/model_39.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 40 [0/1082 (0%)]\tLoss: 0.000330\n",
      "Train Epoch: 40 [640/1082 (59%)]\tLoss: 0.000263\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0692, Accuracy: 45/103 (44%)\n",
      "Saved model to experiment/model_40.pth. You can run `python evaluate.py --model experiment/model_40.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 41 [0/1082 (0%)]\tLoss: 0.000228\n",
      "Train Epoch: 41 [640/1082 (59%)]\tLoss: 0.000980\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0700, Accuracy: 46/103 (45%)\n",
      "Saved model to experiment/model_41.pth. You can run `python evaluate.py --model experiment/model_41.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 42 [0/1082 (0%)]\tLoss: 0.000037\n",
      "Train Epoch: 42 [640/1082 (59%)]\tLoss: 0.000576\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0687, Accuracy: 46/103 (45%)\n",
      "Saved model to experiment/model_42.pth. You can run `python evaluate.py --model experiment/model_42.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 43 [0/1082 (0%)]\tLoss: 0.000595\n",
      "Train Epoch: 43 [640/1082 (59%)]\tLoss: 0.000424\n",
      "\\Training set: ccuracy: 1081/1082\n",
      "\n",
      "Validation set: Average loss: 0.0709, Accuracy: 46/103 (45%)\n",
      "Saved model to experiment/model_43.pth. You can run `python evaluate.py --model experiment/model_43.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 44 [0/1082 (0%)]\tLoss: 0.000309\n",
      "Train Epoch: 44 [640/1082 (59%)]\tLoss: 0.000132\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0709, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_44.pth. You can run `python evaluate.py --model experiment/model_44.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 45 [0/1082 (0%)]\tLoss: 0.000109\n",
      "Train Epoch: 45 [640/1082 (59%)]\tLoss: 0.000570\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0770, Accuracy: 45/103 (44%)\n",
      "Saved model to experiment/model_45.pth. You can run `python evaluate.py --model experiment/model_45.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 46 [0/1082 (0%)]\tLoss: 0.000150\n",
      "Train Epoch: 46 [640/1082 (59%)]\tLoss: 0.000054\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0757, Accuracy: 45/103 (44%)\n",
      "Saved model to experiment/model_46.pth. You can run `python evaluate.py --model experiment/model_46.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 47 [0/1082 (0%)]\tLoss: 0.000125\n",
      "Train Epoch: 47 [640/1082 (59%)]\tLoss: 0.000048\n",
      "\\Training set: ccuracy: 1082/1082\n",
      "\n",
      "Validation set: Average loss: 0.0743, Accuracy: 45/103 (44%)\n",
      "Saved model to experiment/model_47.pth. You can run `python evaluate.py --model experiment/model_47.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 48 [0/1082 (0%)]\tLoss: 0.021769\n",
      "Train Epoch: 48 [640/1082 (59%)]\tLoss: 0.077020\n",
      "\\Training set: ccuracy: 1066/1082\n",
      "\n",
      "Validation set: Average loss: 0.0847, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_48.pth. You can run `python evaluate.py --model experiment/model_48.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 49 [0/1082 (0%)]\tLoss: 0.047033\n",
      "Train Epoch: 49 [640/1082 (59%)]\tLoss: 0.015733\n",
      "\\Training set: ccuracy: 1065/1082\n",
      "\n",
      "Validation set: Average loss: 0.0673, Accuracy: 45/103 (44%)\n",
      "Saved model to experiment/model_49.pth. You can run `python evaluate.py --model experiment/model_49.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 50 [0/1082 (0%)]\tLoss: 0.005479\n",
      "Train Epoch: 50 [640/1082 (59%)]\tLoss: 0.041687\n",
      "\\Training set: ccuracy: 1077/1082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.0638, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_50.pth. You can run `python evaluate.py --model experiment/model_50.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "CPU- Time of execution : 3971.390746116638 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "%run main.py --epochs=50 --cgpu='CPU' --lr=0.14\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
    "\n",
    "print('CPU- Time of execution :',time.time()-start,'s')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even after 50 epochs, the accuracy is really good on the training data, but saturates around 48% for the validation : there is **overfitting** ! <br/>\n",
    "To try and avoid that, and increase the accuracy, we will try to :\n",
    "- switch to a ResNet18,\n",
    "- augment the dataset, \n",
    "- resize the pictures to a bigger size,\n",
    "- freeze some layers of the Net. We will begin by freezing all of them except the last one, and progressively unfreeze them from the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Expanding the database to reduce overfitting\n",
    "We created new training data by adding rescaled, rotated and shifted pictures of the original ones : cf. *data.py*.\n",
    "It modifies the pictures by doing randomly:\n",
    "- a change of the scale, size and ratio by modifying them randomly and recroping to get 64x64 px \n",
    "- a rotation of -45 to +45 degrees and a potential vertical flip to represent possible positions of the bord,\n",
    "- a potential change of perspective\n",
    "\n",
    "We modified the *main.py* file so that we can choose in the arguments if we want to use an augmented dataset or not.\n",
    "\n",
    "Let's try to finetune a ResNet18 (all parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\alixa/.cache\\torch\\checkpoints\\resnet18-5c106cde.pth\n",
      "100%|| 44.7M/44.7M [00:15<00:00, 3.00MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbb852bb6294ec98092d93c46c387cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "#training dataset\n",
    "training_set = torch.utils.data.DataLoader(\n",
    "torch.utils.data.ConcatDataset([\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms),\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms_2)]), batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "#Model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 20)\n",
    "\n",
    "\n",
    "#Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=args.momentum)\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion)\n",
    "lr_finder.range_test(train_loader=training_set,val_loader=None, end_lr=100, num_iter=100)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest lost is : 2.61430686391492 reached for LR = 0.11220184543019632\n"
     ]
    }
   ],
   "source": [
    "lrs = lr_finder.history[\"lr\"]#avoid the first small values\n",
    "losses = lr_finder.history[\"loss\"]\n",
    "\n",
    "print('The smallest lost is :',np.min(losses),'reached for LR =',lrs[np.argmin(losses)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Train Epoch: 1 [0/2164 (0%)]\tLoss: 3.290512\n",
      "Train Epoch: 1 [640/2164 (29%)]\tLoss: 4.016858\n",
      "Train Epoch: 1 [1280/2164 (59%)]\tLoss: 3.646543\n",
      "Train Epoch: 1 [1920/2164 (88%)]\tLoss: 3.285409\n",
      "Training set: Accuracy: 239/2164\n",
      "\n",
      "Validation set: Average loss: 0.3679, Accuracy: 8/103 (8%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/2164 (0%)]\tLoss: 3.477355\n",
      "Train Epoch: 2 [640/2164 (29%)]\tLoss: 2.812068\n",
      "Train Epoch: 2 [1280/2164 (59%)]\tLoss: 2.614039\n",
      "Train Epoch: 2 [1920/2164 (88%)]\tLoss: 2.290019\n",
      "Training set: Accuracy: 444/2164\n",
      "\n",
      "Validation set: Average loss: 0.0514, Accuracy: 31/103 (30%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/2164 (0%)]\tLoss: 2.212065\n",
      "Train Epoch: 3 [640/2164 (29%)]\tLoss: 2.369624\n",
      "Train Epoch: 3 [1280/2164 (59%)]\tLoss: 2.133758\n",
      "Train Epoch: 3 [1920/2164 (88%)]\tLoss: 2.300337\n",
      "Training set: Accuracy: 727/2164\n",
      "\n",
      "Validation set: Average loss: 0.0470, Accuracy: 36/103 (35%)\n",
      "Saved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 4 [0/2164 (0%)]\tLoss: 1.712269\n",
      "Train Epoch: 4 [640/2164 (29%)]\tLoss: 1.759690\n",
      "Train Epoch: 4 [1280/2164 (59%)]\tLoss: 1.562519\n",
      "Train Epoch: 4 [1920/2164 (88%)]\tLoss: 1.708219\n",
      "Training set: Accuracy: 1037/2164\n",
      "\n",
      "Validation set: Average loss: 0.0315, Accuracy: 51/103 (50%)\n",
      "Saved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 5 [0/2164 (0%)]\tLoss: 1.417576\n",
      "Train Epoch: 5 [640/2164 (29%)]\tLoss: 1.228338\n",
      "Train Epoch: 5 [1280/2164 (59%)]\tLoss: 1.699577\n",
      "Train Epoch: 5 [1920/2164 (88%)]\tLoss: 1.136757\n",
      "Training set: Accuracy: 1120/2164\n",
      "\n",
      "Validation set: Average loss: 0.0397, Accuracy: 45/103 (44%)\n",
      "Saved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 6 [0/2164 (0%)]\tLoss: 1.293744\n",
      "Train Epoch: 6 [640/2164 (29%)]\tLoss: 1.223266\n",
      "Train Epoch: 6 [1280/2164 (59%)]\tLoss: 1.131401\n",
      "Train Epoch: 6 [1920/2164 (88%)]\tLoss: 1.409767\n",
      "Training set: Accuracy: 1266/2164\n",
      "\n",
      "Validation set: Average loss: 0.0421, Accuracy: 49/103 (48%)\n",
      "Saved model to experiment/model_6.pth. You can run `python evaluate.py --model experiment/model_6.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 7 [0/2164 (0%)]\tLoss: 0.950636\n",
      "Train Epoch: 7 [640/2164 (29%)]\tLoss: 1.047238\n",
      "Train Epoch: 7 [1280/2164 (59%)]\tLoss: 1.234109\n",
      "Train Epoch: 7 [1920/2164 (88%)]\tLoss: 0.883652\n",
      "Training set: Accuracy: 1403/2164\n",
      "\n",
      "Validation set: Average loss: 0.0362, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_7.pth. You can run `python evaluate.py --model experiment/model_7.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 8 [0/2164 (0%)]\tLoss: 0.836159\n",
      "Train Epoch: 8 [640/2164 (29%)]\tLoss: 0.947004\n",
      "Train Epoch: 8 [1280/2164 (59%)]\tLoss: 0.748233\n",
      "Train Epoch: 8 [1920/2164 (88%)]\tLoss: 1.114752\n",
      "Training set: Accuracy: 1473/2164\n",
      "\n",
      "Validation set: Average loss: 0.0414, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_8.pth. You can run `python evaluate.py --model experiment/model_8.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 9 [0/2164 (0%)]\tLoss: 0.930865\n",
      "Train Epoch: 9 [640/2164 (29%)]\tLoss: 1.031320\n",
      "Train Epoch: 9 [1280/2164 (59%)]\tLoss: 0.861378\n",
      "Train Epoch: 9 [1920/2164 (88%)]\tLoss: 0.602501\n",
      "Training set: Accuracy: 1565/2164\n",
      "\n",
      "Validation set: Average loss: 0.0462, Accuracy: 49/103 (48%)\n",
      "Saved model to experiment/model_9.pth. You can run `python evaluate.py --model experiment/model_9.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 10 [0/2164 (0%)]\tLoss: 0.631046\n",
      "Train Epoch: 10 [640/2164 (29%)]\tLoss: 0.807051\n",
      "Train Epoch: 10 [1280/2164 (59%)]\tLoss: 0.727433\n",
      "Train Epoch: 10 [1920/2164 (88%)]\tLoss: 0.646767\n",
      "Training set: Accuracy: 1626/2164\n",
      "\n",
      "Validation set: Average loss: 0.0405, Accuracy: 55/103 (53%)\n",
      "Saved model to experiment/model_10.pth. You can run `python evaluate.py --model experiment/model_10.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 11 [0/2164 (0%)]\tLoss: 0.632047\n",
      "Train Epoch: 11 [640/2164 (29%)]\tLoss: 0.711935\n",
      "Train Epoch: 11 [1280/2164 (59%)]\tLoss: 0.758316\n",
      "Train Epoch: 11 [1920/2164 (88%)]\tLoss: 0.867599\n",
      "Training set: Accuracy: 1629/2164\n",
      "\n",
      "Validation set: Average loss: 0.0345, Accuracy: 57/103 (55%)\n",
      "Saved model to experiment/model_11.pth. You can run `python evaluate.py --model experiment/model_11.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 12 [0/2164 (0%)]\tLoss: 0.633480\n",
      "Train Epoch: 12 [640/2164 (29%)]\tLoss: 0.489459\n",
      "Train Epoch: 12 [1280/2164 (59%)]\tLoss: 0.629319\n",
      "Train Epoch: 12 [1920/2164 (88%)]\tLoss: 0.624242\n",
      "Training set: Accuracy: 1665/2164\n",
      "\n",
      "Validation set: Average loss: 0.0424, Accuracy: 51/103 (50%)\n",
      "Saved model to experiment/model_12.pth. You can run `python evaluate.py --model experiment/model_12.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 13 [0/2164 (0%)]\tLoss: 0.488710\n",
      "Train Epoch: 13 [640/2164 (29%)]\tLoss: 0.678782\n",
      "Train Epoch: 13 [1280/2164 (59%)]\tLoss: 0.661056\n",
      "Train Epoch: 13 [1920/2164 (88%)]\tLoss: 0.684408\n",
      "Training set: Accuracy: 1681/2164\n",
      "\n",
      "Validation set: Average loss: 0.0451, Accuracy: 49/103 (48%)\n",
      "Saved model to experiment/model_13.pth. You can run `python evaluate.py --model experiment/model_13.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 14 [0/2164 (0%)]\tLoss: 0.509896\n",
      "Train Epoch: 14 [640/2164 (29%)]\tLoss: 0.620997\n",
      "Train Epoch: 14 [1280/2164 (59%)]\tLoss: 0.729711\n",
      "Train Epoch: 14 [1920/2164 (88%)]\tLoss: 0.714170\n",
      "Training set: Accuracy: 1740/2164\n",
      "\n",
      "Validation set: Average loss: 0.0379, Accuracy: 52/103 (50%)\n",
      "Saved model to experiment/model_14.pth. You can run `python evaluate.py --model experiment/model_14.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 15 [0/2164 (0%)]\tLoss: 0.582375\n",
      "Train Epoch: 15 [640/2164 (29%)]\tLoss: 0.640522\n",
      "Train Epoch: 15 [1280/2164 (59%)]\tLoss: 0.722152\n",
      "Train Epoch: 15 [1920/2164 (88%)]\tLoss: 1.295604\n",
      "Training set: Accuracy: 1727/2164\n",
      "\n",
      "Validation set: Average loss: 0.0508, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_15.pth. You can run `python evaluate.py --model experiment/model_15.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 16 [0/2164 (0%)]\tLoss: 0.559301\n",
      "Train Epoch: 16 [640/2164 (29%)]\tLoss: 0.423683\n",
      "Train Epoch: 16 [1280/2164 (59%)]\tLoss: 0.561324\n",
      "Train Epoch: 16 [1920/2164 (88%)]\tLoss: 0.605479\n",
      "Training set: Accuracy: 1782/2164\n",
      "\n",
      "Validation set: Average loss: 0.0476, Accuracy: 49/103 (48%)\n",
      "Saved model to experiment/model_16.pth. You can run `python evaluate.py --model experiment/model_16.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 17 [0/2164 (0%)]\tLoss: 0.631317\n",
      "Train Epoch: 17 [640/2164 (29%)]\tLoss: 0.266041\n",
      "Train Epoch: 17 [1280/2164 (59%)]\tLoss: 0.394085\n",
      "Train Epoch: 17 [1920/2164 (88%)]\tLoss: 0.461055\n",
      "Training set: Accuracy: 1853/2164\n",
      "\n",
      "Validation set: Average loss: 0.0390, Accuracy: 55/103 (53%)\n",
      "Saved model to experiment/model_17.pth. You can run `python evaluate.py --model experiment/model_17.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 18 [0/2164 (0%)]\tLoss: 0.555225\n",
      "Train Epoch: 18 [640/2164 (29%)]\tLoss: 0.395083\n",
      "Train Epoch: 18 [1280/2164 (59%)]\tLoss: 0.698305\n",
      "Train Epoch: 18 [1920/2164 (88%)]\tLoss: 0.695373\n",
      "Training set: Accuracy: 1839/2164\n",
      "\n",
      "Validation set: Average loss: 0.0486, Accuracy: 54/103 (52%)\n",
      "Saved model to experiment/model_18.pth. You can run `python evaluate.py --model experiment/model_18.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 19 [0/2164 (0%)]\tLoss: 0.478821\n",
      "Train Epoch: 19 [640/2164 (29%)]\tLoss: 0.323602\n",
      "Train Epoch: 19 [1280/2164 (59%)]\tLoss: 0.333614\n",
      "Train Epoch: 19 [1920/2164 (88%)]\tLoss: 0.409197\n",
      "Training set: Accuracy: 1862/2164\n",
      "\n",
      "Validation set: Average loss: 0.0481, Accuracy: 55/103 (53%)\n",
      "Saved model to experiment/model_19.pth. You can run `python evaluate.py --model experiment/model_19.pth` to generate the Kaggle formatted csv file\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [0/2164 (0%)]\tLoss: 0.521486\n",
      "Train Epoch: 20 [640/2164 (29%)]\tLoss: 0.388200\n",
      "Train Epoch: 20 [1280/2164 (59%)]\tLoss: 0.490635\n",
      "Train Epoch: 20 [1920/2164 (88%)]\tLoss: 0.234678\n",
      "Training set: Accuracy: 1880/2164\n",
      "\n",
      "Validation set: Average loss: 0.0550, Accuracy: 50/103 (49%)\n",
      "Saved model to experiment/model_20.pth. You can run `python evaluate.py --model experiment/model_20.pth` to generate the Kaggle formatted csv file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run main.py --epochs=20 --cgpu='CPU' --lr=0.11 --augmented=True\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get results a bit better with less epochs :we will use an augmented dataset from now on; but the model can still be improved.<br/>\n",
    "Let's try freezing some layers + resizing the pictures to a bigger size by modifying the *data_transform* functions !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Freezing layers (+ resizing the pictures to 256x256)\n",
    "\n",
    "Pictures have been resized !\n",
    "\n",
    "#### 2.3.1 Counting the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the net : 10\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 20)\n",
    "\n",
    "layer = 0\n",
    "for name, child in model.named_children():\n",
    "    layer += 1\n",
    "    \n",
    "print('Number of layers in the net :',layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Freezing all layers except the last\n",
    "(The training should be faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4bff16379a41138052d4a9e6ca03d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "#training dataset\n",
    "training_set = torch.utils.data.DataLoader(\n",
    "torch.utils.data.ConcatDataset([\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms),\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms_2)]), batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "#Model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 20)\n",
    "\n",
    "# We freeze the 9 first layers\n",
    "layer = 0\n",
    "for name, child in model.named_children():\n",
    "    layer += 1\n",
    "    if layer <= 9:\n",
    "        for name2, params in child.named_parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "\n",
    "#Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=args.momentum)\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion)\n",
    "lr_finder.range_test(train_loader=training_set,val_loader=None, end_lr=100, num_iter=100)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest lost is : 2.700276094230675 reached for LR = 0.14125375446227542\n"
     ]
    }
   ],
   "source": [
    "lrs = lr_finder.history[\"lr\"]#avoid the first small values\n",
    "losses = lr_finder.history[\"loss\"]\n",
    "\n",
    "print('The smallest lost is :',np.min(losses),'reached for LR =',lrs[np.argmin(losses)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Train Epoch: 1 [0/2164 (0%)]\tLoss: 3.112243\n",
      "Train Epoch: 1 [640/2164 (29%)]\tLoss: 12.865611\n",
      "Train Epoch: 1 [1280/2164 (59%)]\tLoss: 6.955349\n",
      "Train Epoch: 1 [1920/2164 (88%)]\tLoss: 3.630522\n",
      "Training set: Accuracy: 638/2164\n",
      "\n",
      "Validation set: Average loss: 0.0445, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/2164 (0%)]\tLoss: 2.277579\n",
      "Train Epoch: 2 [640/2164 (29%)]\tLoss: 1.859010\n",
      "Train Epoch: 2 [1280/2164 (59%)]\tLoss: 1.042526\n",
      "Train Epoch: 2 [1920/2164 (88%)]\tLoss: 1.272944\n",
      "Training set: Accuracy: 1532/2164\n",
      "\n",
      "Validation set: Average loss: 0.0380, Accuracy: 52/103 (50%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/2164 (0%)]\tLoss: 1.487924\n",
      "Train Epoch: 3 [640/2164 (29%)]\tLoss: 0.560002\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "%run main.py --epochs=10 --cgpu='CPU' --lr=0.14 --augmented=True\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
    "\n",
    "print('CPU- Time of execution :',time.time()-start,'s')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saved the model with best validation error and lower accuracy on the training :model4 (to avoid overifitting) to 'experiment/model_res18_saved1' and model16 to 'experiment/model_res18_saved2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d8d618430745049d4dd6f144ddfc3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "#training dataset\n",
    "training_set = torch.utils.data.DataLoader(\n",
    "torch.utils.data.ConcatDataset([\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms),\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms_2)]), batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "#Model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 20)\n",
    "\n",
    "# We freeze the 9 first layers\n",
    "layer = 0\n",
    "for name, child in model.named_children():\n",
    "    layer += 1\n",
    "    if layer <= 9:\n",
    "        for name2, params in child.named_parameters():\n",
    "            params.requires_grad = False\n",
    "model.load_state_dict(torch.load('experiment/model_res18_saved1.pth'))\n",
    "            \n",
    "\n",
    "#Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=args.momentum)\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion)\n",
    "lr_finder.range_test(train_loader=training_set,val_loader=None, end_lr=100, num_iter=100)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = lr_finder.history[\"lr\"]#avoid the first small values\n",
    "losses = lr_finder.history[\"loss\"]\n",
    "\n",
    "print('The smallest lost is :',np.min(losses),'reached for LR =',lrs[np.argmin(losses)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Freezing the top half of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "#training dataset\n",
    "training_set = torch.utils.data.DataLoader(\n",
    "torch.utils.data.ConcatDataset([\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms),\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms_2)]), batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "#Model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 20)\n",
    "\n",
    "# We freeze the 5 first layers\n",
    "layer = 0\n",
    "for name, child in model.named_children():\n",
    "    layer += 1\n",
    "    if layer <= 5:\n",
    "        for name2, params in child.named_parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "\n",
    "#Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=args.momentum)\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion)\n",
    "lr_finder.range_test(train_loader=training_set,val_loader=None, end_lr=100, num_iter=100)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest lost is : 2.6780490179806775 reached for LR = 0.08912509381337456\n"
     ]
    }
   ],
   "source": [
    "lrs = lr_finder.history[\"lr\"]#avoid the first small values\n",
    "losses = lr_finder.history[\"loss\"]\n",
    "\n",
    "print('The smallest lost is :',np.min(losses),'reached for LR =',lrs[np.argmin(losses)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Train Epoch: 1 [0/2164 (0%)]\tLoss: 3.593346\n",
      "Train Epoch: 1 [640/2164 (29%)]\tLoss: 4.347428\n",
      "Train Epoch: 1 [1280/2164 (59%)]\tLoss: 3.044508\n",
      "Train Epoch: 1 [1920/2164 (88%)]\tLoss: 2.800216\n",
      "Training set: Accuracy: 249/2164\n",
      "\n",
      "Validation set: Average loss: 0.0695, Accuracy: 13/103 (13%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/2164 (0%)]\tLoss: 2.613709\n",
      "Train Epoch: 2 [640/2164 (29%)]\tLoss: 2.507537\n",
      "Train Epoch: 2 [1280/2164 (59%)]\tLoss: 2.133052\n",
      "Train Epoch: 2 [1920/2164 (88%)]\tLoss: 1.920328\n",
      "Training set: Accuracy: 588/2164\n",
      "\n",
      "Validation set: Average loss: 0.0464, Accuracy: 30/103 (29%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/2164 (0%)]\tLoss: 1.750473\n",
      "Train Epoch: 3 [640/2164 (29%)]\tLoss: 1.663415\n",
      "Train Epoch: 3 [1280/2164 (59%)]\tLoss: 1.599991\n",
      "Train Epoch: 3 [1920/2164 (88%)]\tLoss: 1.398291\n",
      "Training set: Accuracy: 912/2164\n",
      "\n",
      "Validation set: Average loss: 0.0379, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 4 [0/2164 (0%)]\tLoss: 1.536361\n",
      "Train Epoch: 4 [640/2164 (29%)]\tLoss: 1.174259\n",
      "Train Epoch: 4 [1280/2164 (59%)]\tLoss: 1.196311\n",
      "Train Epoch: 4 [1920/2164 (88%)]\tLoss: 1.106254\n",
      "Training set: Accuracy: 1201/2164\n",
      "\n",
      "Validation set: Average loss: 0.0371, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 5 [0/2164 (0%)]\tLoss: 1.511347\n",
      "Train Epoch: 5 [640/2164 (29%)]\tLoss: 1.877411\n",
      "Train Epoch: 5 [1280/2164 (59%)]\tLoss: 1.159395\n",
      "Train Epoch: 5 [1920/2164 (88%)]\tLoss: 0.833840\n",
      "Training set: Accuracy: 1274/2164\n",
      "\n",
      "Validation set: Average loss: 0.0347, Accuracy: 50/103 (49%)\n",
      "Saved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 6 [0/2164 (0%)]\tLoss: 1.055796\n",
      "Train Epoch: 6 [640/2164 (29%)]\tLoss: 0.720910\n",
      "Train Epoch: 6 [1280/2164 (59%)]\tLoss: 1.028839\n",
      "Train Epoch: 6 [1920/2164 (88%)]\tLoss: 0.823571\n",
      "Training set: Accuracy: 1502/2164\n",
      "\n",
      "Validation set: Average loss: 0.0432, Accuracy: 48/103 (47%)\n",
      "Saved model to experiment/model_6.pth. You can run `python evaluate.py --model experiment/model_6.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 7 [0/2164 (0%)]\tLoss: 0.820794\n",
      "Train Epoch: 7 [640/2164 (29%)]\tLoss: 0.658599\n",
      "Train Epoch: 7 [1280/2164 (59%)]\tLoss: 0.931430\n",
      "Train Epoch: 7 [1920/2164 (88%)]\tLoss: 1.041546\n",
      "Training set: Accuracy: 1610/2164\n",
      "\n",
      "Validation set: Average loss: 0.0462, Accuracy: 47/103 (46%)\n",
      "Saved model to experiment/model_7.pth. You can run `python evaluate.py --model experiment/model_7.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 8 [0/2164 (0%)]\tLoss: 0.582501\n",
      "Train Epoch: 8 [640/2164 (29%)]\tLoss: 0.651778\n",
      "Train Epoch: 8 [1280/2164 (59%)]\tLoss: 0.425283\n",
      "Train Epoch: 8 [1920/2164 (88%)]\tLoss: 0.687015\n",
      "Training set: Accuracy: 1670/2164\n",
      "\n",
      "Validation set: Average loss: 0.0471, Accuracy: 52/103 (50%)\n",
      "Saved model to experiment/model_8.pth. You can run `python evaluate.py --model experiment/model_8.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 9 [0/2164 (0%)]\tLoss: 0.528077\n",
      "Train Epoch: 9 [640/2164 (29%)]\tLoss: 0.438286\n",
      "Train Epoch: 9 [1280/2164 (59%)]\tLoss: 0.730547\n",
      "Train Epoch: 9 [1920/2164 (88%)]\tLoss: 0.598592\n",
      "Training set: Accuracy: 1747/2164\n",
      "\n",
      "Validation set: Average loss: 0.0466, Accuracy: 50/103 (49%)\n",
      "Saved model to experiment/model_9.pth. You can run `python evaluate.py --model experiment/model_9.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 10 [0/2164 (0%)]\tLoss: 0.370254\n",
      "Train Epoch: 10 [640/2164 (29%)]\tLoss: 0.505386\n",
      "Train Epoch: 10 [1280/2164 (59%)]\tLoss: 0.638997\n",
      "Train Epoch: 10 [1920/2164 (88%)]\tLoss: 0.488983\n",
      "Training set: Accuracy: 1764/2164\n",
      "\n",
      "Validation set: Average loss: 0.0497, Accuracy: 51/103 (50%)\n",
      "Saved model to experiment/model_10.pth. You can run `python evaluate.py --model experiment/model_10.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "CPU- Time of execution : 1287.0346052646637 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "%run main.py --epochs=10 --cgpu='CPU' --lr=0.089 --augmented=True\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
    "\n",
    "print('CPU- Time of execution :',time.time()-start,'s')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Freezing the bottom half of the layer (except the last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae24ca5833a9481da68dba58ea268ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEOCAYAAABmVAtTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmUXOV55/Hv09X7rt4koQWtIBaztjEE22EzAewBJyYxeGwH2xkFOw7JeCaJnczxTHyOJ8tJztgOJ+bIOA4YGy94CSaAAdsYg1ncgABBC1CLpSX1Uq1WL9WtXqrrmT/qVlM0Lalb6lu3uvr3OadO3br3vVWPUFE/3Xvf+77m7oiIiAAURV2AiIjkD4WCiIhMUyiIiMg0hYKIiExTKIiIyDSFgoiITFMoiIjINIWCiIhMUyiIiMg0hYKIiEwrjrqA+WpqavJ169ZFXYaIyKLy5JNP9rl785HahRYKZnYi8N2sVRuAz7v7l7LaGPBl4ApgFLjO3Z863PuuW7eOtra2ECoWESlcZvbaXNqFFgru/iJwRlBMDNgL/GhGs8uBzcHjHcBXg2cREYlArq4pXAx0uPvMpLoKuNXTHgPqzWxljmoSEZEZchUK1wC3z7J+FdCZ9XpPsO5NzGyrmbWZWVs8Hg+pRBERCT0UzKwUuBL4/mybZ1n3lgke3H2bu7e6e2tz8xGvk4iIyFHKxZHC5cBT7t4zy7Y9wJqs16uBfTmoSUREZpGLULiW2U8dAdwJfNTSzgUG3b0rBzWJiMgsQg0FM6sE3gP8MGvd9WZ2ffDybmA3sAv4GvCpMOsREVmsfvp8N6/0jYT+OaHevObuo0DjjHU3ZS078Cdh1iAisthNTqX49Lef4hPv3MBnL98S6mdpmAsRkTzXEU8wOeWctLIm9M9SKIiI5LmdXcMAnLSyNvTPUiiIiOS59q4hSmNFbGiqCv2zFAoiInnuha4hNi+vpjgW/k+2QkFEJM/t7B7OyakjUCiIiOS1vsQ48eFxtqwI/yIzKBRERPJa5iLzyTpSEBGR9q4hALYoFEREpL1riOW1ZTRUlebk8xQKIiJ5rD2HF5lBoSAikrcmkil29Q6zZYVCQURkydvdl7vhLTIUCiIieSpzkTlXPY9AoSAikrfau4YpLS5ifQ6Gt8hQKIiI5Kn2riFOyNHwFhkKBRGRPNXelduLzBD+zGv1ZnaHme00s3YzO2/G9gvMbNDMtgePz4dZj4jIYhEfHqcvMZ7T7qgQ8sxrwJeBe939ajMrBSpnafMrd39fyHWIiCwqO7vTF5lz2fMIQgwFM6sF3g1cB+DuE8BEWJ8nIlJIMj2PTiqg00cbgDjwDTN72sxuNrPZLqGfZ2bPmNk9ZnZKiPWIiCwaO7uGWVFbzrIcDW+REWYoFANnAV919zOBEeCzM9o8BRzv7qcD/wL8eLY3MrOtZtZmZm3xeDzEkkVE8sMLXUNsyfGpIwg3FPYAe9z98eD1HaRDYpq7D7l7Ili+Gygxs6aZb+Tu29y91d1bm5ubQyxZRCR6E8kUHfFEzi8yQ4ih4O7dQKeZnRisuhh4IbuNma0wMwuWzwnq2R9WTSIii0FHPD28Ra4m1skWdu+jPwW+FfQ82g18zMyuB3D3m4CrgU+aWRI4CFzj7h5yTSIieS2K4S0yQg0Fd98OtM5YfVPW9huBG8OsQURksdnZnfvhLTJ0R7OISJ6JYniLDIWCiEieae8ayvn9CRkKBRGRPJIe3mIiZ3Myz6RQEBHJI9N3MkdwjwIoFERE8sr0mEc6fSQiIu0RDW+RoVAQEckj7V1DkZ06AoWCiEjemEim2NWbiOwiMygURETyxq7eBMmURzLmUYZCQUQkT7wxvIVOH4mILHk7u4coLS5iXWPuh7fIUCiIiOSJ9q5hTlxeE8nwFhkKBRGRPLGzeyiS4bKzKRRERPJA7/AYfYmJSC8yg0JBRCQvtHcNA0QyBWc2hYKISB7YGeHEOtkUCiIieaC9a4iVdeXUV0YzvEVGqKFgZvVmdoeZ7TSzdjM7b8Z2M7OvmNkuM3vWzM4Ksx4RkXy1s3s48ovMEP6RwpeBe919C3A60D5j++XA5uCxFfhqyPWIiOSd8eQUu3oTkV9khhBDwcxqgXcDXwdw9wl3H5jR7CrgVk97DKg3s5Vh1SQiko86ekdIpjzSMY8ywjxS2ADEgW+Y2dNmdrOZzbxNbxXQmfV6T7BORGTJ2BVPALC5pTriSsINhWLgLOCr7n4mMAJ8dkYbm2U/n7nCzLaaWZuZtcXj8YWvVEQkQh29CcxgfVN0w1tkhBkKe4A97v548PoO0iExs82arNergX0z38jdt7l7q7u3Njc3h1KsiEhUOuIJ1iyrpLwkFnUp4YWCu3cDnWZ2YrDqYuCFGc3uBD4a9EI6Fxh0966wahIRyUcd8RE2Nkd/lADpUzxh+lPgW2ZWCuwGPmZm1wO4+03A3cAVwC5gFPhYyPWIiOSVqZSzO57g/I2NUZcChBwK7r4daJ2x+qas7Q78SZg1iIjks30DBxlPptiUBxeZQXc0i4hEKtPzaKNCQUREOnqDUGhWKIiILHkd8QTLKktoqIp2zKMMhYKISIQ6ekfy5noCKBRERCLVEU/kzakjUCiIiETmwMgE+0cmFAoiIgK7+zI9j/LjxjVQKIiIRGZXnvU8AoWCiEhkOuIjlBYXsXpZZdSlTFMoiIhEpKM3wYamKmJFsw0YHQ2FgohIRPKt5xEoFEREIjE2OcXr/aN5MzpqhkJBRCQCr+0fJeX5M+ZRhkJBRCQCHfH863kECgURkUhkBsLboNNHIiKyK55gVX0FlaVhz3U2PwoFEZEIdMQTeXc9AUIOBTN71cyeM7PtZtY2y/YLzGww2L7dzD4fZj0iIvkglXI6evNnXuZsuThuudDd+w6z/Vfu/r4c1CEikhe6h8Y4ODmVdxeZQaePRERyLl97HkH4oeDAfWb2pJltPUSb88zsGTO7x8xOCbkeEZHIZQbCy6fJdTLCPn10vrvvM7MW4H4z2+nuD2Vtfwo43t0TZnYF8GNg88w3CQJlK8DatWtDLllEJFwd8QS15cU0VefHFJzZQj1ScPd9wXMv8CPgnBnbh9w9ESzfDZSYWdMs77PN3VvdvbW5uTnMkkVEQtfRO8LGlmrM8mcgvIzQQsHMqsysJrMMXArsmNFmhQX/VczsnKCe/WHVJCKSD/JxILyMME8fLQd+FPzmFwPfdvd7zex6AHe/Cbga+KSZJYGDwDXu7iHWJCISqaGxSXqHx/PyegKEGAruvhs4fZb1N2Ut3wjcGFYNIiL5piMPZ1vLpi6pIiI51BEfAcjLG9dAoSAiklMd8QQlMWNNQ/5MwZlNoSAikkO7ehMc31hFSSw/f37zsyoRkQLVEU+wKU+vJ4BCQUQkZyanUry+f5SNLfl5PQEUCiIiOfPa/lGSKc/bnkegUBARyZlded4dFRQKIiI5Mz06ap7euAYKBRGRnOmIJ1hRW051WX5NwZlNoSAikiMd8ZG8vsgMCgURkZxwd3b35u9AeBkKBRGRHOgdHmd4PJm3A+FlzCkUzGyjmZUFyxeY2Q1mVh9uaSIihSPfB8LLmOuRwg+AKTPbBHwdWA98O7SqREQKTD7Py5xtrqGQcvck8LvAl9z9vwMrwytLRKSwdMRHqC4rZnltWdSlHNZcQ2HSzK4F/hC4K1hXEk5JIiKFZ1dvgo3NVXk5BWe2uYbCx4DzgC+6+ytmth64LbyyREQKSz5PwZltTndQuPsLwA0AZrYMqHH3vz/Sfmb2KjAMTAFJd2+dsd2ALwNXAKPAde7+1Hz+ACIi+S4xnqRrcCyv72TOmFMomNmDwJVB++1A3Mx+6e6fmcPuF7p73yG2XQ5sDh7vAL4aPIuIFIxX8ny2tWxzPX1U5+5DwO8B33D3s4FLFuDzrwJu9bTHgHoz0wVsESkou+LDQP73PIK5h0Jx8GP9B7xxoXkuHLjPzJ40s62zbF8FdGa93hOsExEpGL96qY+6ihLWNeX/kcJcR2X6AvBT4BF3/42ZbQBensN+57v7PjNrAe43s53u/lDW9tkuw/vMFUGgbAVYu3btHEsWEYneRDLF/e09/M4pK/J2Cs5sc6rQ3b/v7qe5+yeD17vd/QNz2G9f8NwL/Ag4Z0aTPcCarNergX2zvM82d29199bm5ua5lCwikhce6ehjeCzJFW9bEXUpczLXYS5Wm9mPzKzXzHrM7AdmtvoI+1SZWU1mGbgU2DGj2Z3ARy3tXGDQ3buO4s8hIpKX7n2um5qyYs7f1BR1KXMy12OZb5D+AT+O9Dn/nwTrDmc58LCZPQM8Afynu99rZteb2fVBm7uB3cAu4GvAp+ZZv4hI3kpOpbjvhW4uOqmFsuJY1OXMyVyvKTS7e3YI/LuZ/fnhdnD33cDps6y/KWvZgT+ZYw0iIovK46/0c2B0kstPXTydKud6pNBnZh82s1jw+DCwP8zCREQWu7uf66KiJMZvn7B4roXONRQ+Tro7ajfQBVxNeugLERGZxVTK+enzPVy0pYWK0sVx6gjm3vvodXe/0t2b3b3F3d9P+kY2ERGZRdur/fQlxrns1MXR6yjjWDrNzmWICxGRJemeHd2UFRdx4ZaWqEuZl2MJhfwe/1VEJCKplHPvjm7efUIz1WVz7c+TH44lFN5y57GIiMD2PQN0D41x+SI7dQRH6JJqZsPM/uNvQEUoFYmILHL3PNdFScy4+KTlUZcyb4cNBXevyVUhIiKFwN25Z0c3529qoq5i8U1Qmf+jM4mILCLP7xtiz4GDXLGIbljLplAQEVlAdz/XRazIeM/Ji+/UESgUREQWTObU0XkbGllWVRp1OUdFoSAiskBe7Bnmlb6RRXfDWjaFgojIArnnuW7M4NJTFuepI1AoiIgsmHt2dPH2dQ201JRHXcpRUyiIiCyAXb0JXupJLMob1rIpFEREFsC9O9KTRi7m6wmQg1AI5l942szummXbdWYWN7PtweOPwq5HRCQM9+zo5sy19aysW9yDPeTiSOHPgPbDbP+uu58RPG7OQT0iIgvq9f2jPL9vaNHesJYt1FAws9XAewH92ItIwbqnQE4dQfhHCl8C/hJIHabNB8zsWTO7w8zWhFyPiMiCu++FHk45rpY1DZVRl3LMQgsFM3sf0OvuTx6m2U+Ade5+GvAAcMsh3murmbWZWVs8Hg+hWhGRo9OXGOep1w9wySIcEXU2YR4pnA9caWavAt8BLjKz27IbuPt+dx8PXn4NOHu2N3L3be7e6u6tzc2LZwJsESl8v9jZizsKhSNx98+5+2p3XwdcA/zc3T+c3cbMsq/KXMnhL0iLiOSdn7X3sry2jFNX1UZdyoLI+TxxZvYFoM3d7wRuMLMrgSTQD1yX63pERI7WeHKKX70c56ozV2FWGDMU5yQU3P1B4MFg+fNZ6z8HfC4XNYiILLTHdvczMjHFJSe1RF3KgtEdzSIiR+mBF3ooLynitzY2RV3KglEoiIgcBXfnZ+09vGtzM+UlsajLWTAKBRGRo9DeNcy+wbGCOnUECgURkaPys/YeAC7colAQEVnyHtjZy+lr6hf13AmzUSiIiMxT7/AYz3QO8J4CO3UECgURkXn7eXsvABcXyF3M2RQKIiLz9EB7L6vqK9iyoibqUhacQkFEZB7GJqd4eFeci09qKZi7mLMpFERE5uHXHX2MTaYKZgC8mRQKIiLz8EB7L1WlMd6xoSHqUkKhUBARmaPMXczvPqGZsuLCuYs5m0JBRGSOduwdomdovCB7HWUoFERE5uiB9h6KDC48sXAn+1IoiIjM0c929nDW2mU0VpdFXUpoFAoiInPQPTjGjr1DBX3qCBQKIiJz8rOd6QHwCm1U1JlCDwUzi5nZ02Z21yzbyszsu2a2y8weN7N1YdcjInI0Hnihh7UNlWxqqY66lFDl4kjhz4D2Q2z7BHDA3TcB/w/4hxzUIyIyL6MTSR7p2M8lJy0vyLuYs4UaCma2GngvcPMhmlwF3BIs3wFcbIX+X1xEFp2HX+5jIpkq+FNHEP6RwpeAvwRSh9i+CugEcPckMAg0hlyTiMi8/Ky9l5ryYt6+vjDvYs4WWiiY2fuAXnd/8nDNZlnns7zXVjNrM7O2eDy+YDWKiBzJeHKK+9t7uODEFkpihd83J8w/4fnAlWb2KvAd4CIzu21Gmz3AGgAzKwbqgP6Zb+Tu29y91d1bm5sL96YREck/dz/XRf/IBB9sXRN1KTkRWii4++fcfbW7rwOuAX7u7h+e0exO4A+D5auDNm85UhARicqtj77GhuYqzt+0NM5s5/xYyMy+YGZXBi+/DjSa2S7gM8Bnc12PiMih7Ng7yNOvD/Dhdxxf8L2OMopz8SHu/iDwYLD8+az1Y8Dv56IGEZH5uvXRV6koifGBs1dHXUrOFP5VExGRozAwOsF/bN/H+89cRV1FSdTl5IxCQURkFt9v28N4MsVHzzs+6lJySqEgIjJDKuXc9vhrvH3dMk5aWRt1OTmlUBARmeGXL8d5bf8oHzlvXdSl5JxCQURkhtsefY2m6jIuO2VF1KXknEJBRCRLZ/8oP3+xlw+ds4bS4qX3E7n0/sQiIodx2+OvUWTGte9YG3UpkVAoiIgExian+N5vOnnPSctZWVcRdTmRUCiIiATueraLA6OTS64bajaFgohI4JuPvsqmlmrO27g0xjmajUJBRAR4pnOAZ/YM8pFzl844R7NRKIiIkB4Ntao0xu+dtSrqUiKlUBCRJa9/ZIKfPLuP3z1rFTXlS2eco9koFERkyft+WycTyRQfOXdd1KVETqEgIkva5FSK2x5/jXPWN3Diipqoy4mcQkFElrQv/mc7nf0H2fquDVGXkhcUCiKyZH2/rZN///WrfPz89Vxy8vKoy8kLoYWCmZWb2RNm9oyZPW9mfztLm+vMLG5m24PHH4VVj4hItu2dA/zNj3fwWxsb+esrtkRdTt4IczrOceAid0+YWQnwsJnd4+6PzWj3XXf/dIh1iIi8Se/QGH/8zTZaasq48UNnURzTSZOM0ELB3R1IBC9LgoeH9XkiInMxnpzi+tueZOhgkh9+6rdoqCqNuqS8Emo8mlnMzLYDvcD97v74LM0+YGbPmtkdZrYmzHpEZGlzd/7Pnc/z1OsD/NPvn77kZlWbizBPH+HuU8AZZlYP/MjMTnX3HVlNfgLc7u7jZnY9cAtw0cz3MbOtwFaAtWuPbjjbl3uGuXdHN0VFRpEZsSIossyyUWRQHCuiubqM4+orWFVfQW1F8ZK+3V2k0Nz2+Ovc/kQnn7pgI+89bWXU5eSlUEMhw90HzOxB4DJgR9b6/VnNvgb8wyH23wZsA2htbT2qU1Av9gzzz/e/NK99qsuKOa6+fDokjquvoLm6jNqKYmorSqgtL6GuooTaihJqyoopKlKAiOSrJ17p52/vfJ4LT2zmf1x6YtTl5K3QQsHMmoHJIBAqgEuY8aNvZivdvSt4eSXQHlY9V5y6kpe/uIKplOMOU+6k3EmlnJTDVMpJplL0Do2zb+AgezOPAwfZN3iQZ/cM0j8ycZg/L9SUFbOsqpSGqlIaq8poqg6Wq99YzmxrqCpdkrM6iURh38BBPvWtJ1nbUMmXrjmTmP4Bd0hhHimsBG4xsxjpaxffc/e7zOwLQJu73wncYGZXAkmgH7gurGKKiowijJLYEYquq+D0NfWzbhudSHJgdJLB0UkGD04yNBY8B4/Bg5McGJ2kf2SCPQdGeWbPAP0jE0ylZj+4qSkrpiETHFVvBMiK2nKW15azsi79aKwu05dY5CiNTU7xx998krHJFN/ZejZ1FUt7bKMjsXQnocWjtbXV29raoi5jzlIpZ2hskr7EBP0jE+xPjLN/JL3cPzIRLI+zP/HGuuSMEIkVGctrylhRV86KunKqSospjhVREjOKi4ooKTZKiooojhklsSKqSmM0VJe9ETRVpSyrKqVE3e5kCfrcD5/l9ic6ufmjrUv6BjUze9LdW4/ULifXFJayoiKjvrKU+sq5dXtLpZz+0Qm6B8foGhyje2iM7sGD6eXBMXZ2D3NwYorJqfTprslkismUk5xKcYgDkmm15cU0VpdRX1lCdVkxVaXFVJUVU10Wo6oss5x+NARB0lBZyrKqdHtddJfF5j+27+X2Jzr55AUbl3QgzIdCIc8UFRlN1WU0VZdx6qq6ee2bSjkTUylGxpPTRyHpI5A3jk72j0wwODrJ8FiS7sExRsaTJMaTjExMHfI0F0BprIhlVSUsq0wffayqr2BtQyVrGyvTzw2VNFSVKjgkb7zSN8Jf//A5zj5+GZ95zwlRl7NoKBQKSFGRUV4Uo7wkRmN1GZvnsa+7M55MkRhPMjyW5MDoBAeCIDkwOkH/yGT69Wj6FNgvX4rTOzz+pveoKo2xpqGS4xsrWVlXQXNNGS01ZcFzOc016Qvsuj4iYRtPTvHpbz9FcayIr1x7pk6dzoNCQQAwM8pL0oHSVF3GeqqOuM/BiSn2HBjltf2jvN6ffnT2j9IRH+HXu/YzPJ58yz6xIqOxqpTmmrJ0r6yqUhqrS2mqTr9urC6lqSr93FBVSvmRegaIzOL//mc7z+8b4uaPtrKqviLqchYVhYIctYrSGJuX17B5+exj0I9OJOkbnqB3eIz48Di9w+PBc/p1/8gEHb0J+hLjjCdTs75H5vpGY3X6gnljVRkNwfLqZRWsXlbJ6mUV1FWU6NSVAHDvji5uefQ1PvFOjXx6NBQKEprK0mLWNhaztrHysO3cnZGJKfYnxulLTEw/Z66FZHpm7R0Ym75fZGYPrZqyYlYtq2BNQzok1iyrZGVdOcvr0t17m6vLdF/IEtDZP8pf3PEsp6+u468u08inR0OhIJEzs+leT8c3Hvm0lbszMDrJ3oGD7DlwkD0HRqefX98/yiO7+hidmHrLfk3VpbTUlLO8Nt29t6Gq9E09rmYu11WU0FhVqjvVF4mJZIpP3/40ADd+6Cz9I+AoKRRk0TEzlgVdZmfroeXuHBidpHtwjJ6hzGOc7qExeofS3Xyf2zvIgdHJw/a4AiguMlpqylheVz59U+GKYLmltoxllaXUV5ZQX1FKeUmRTmFF6J/ue5FnOgf41/96FmsaDn90KoemUJCCY2bTQ4qcfNyhR8HM9LgaHktOd81NjL+xPDA6SU8QIj1DY7zUM8yvXu4jMcsFdIDS4iLqK0qmQ6KusoTjGyrZvLw6fe2lpZqact1NG4af7+xh20O7+ci5x3PF2zTQ3bFQKMiSld3jqrmmbM77JcbT93j0Do0xcHCSgWDYk4GD6XtABkbTy6/vH+Whl+Jvuoh+XF05m5fXcEIQFCtqy6ksjVFRGqOytJiKksxyTN0o52hXb4LPfO8ZTl5Zy9+896Soy1n0FAoi81RdVsymlmo2tVQfse1UyunsH+WlnmFe7k3wcs8wL/UkeHT3fiYO0eMqoySWvht+XWMl6xqrWN9cxfrGKtY1VbGusYqK0qXZXdfdeaFriPtf6OG+53t4oWuIqtIYN37oTHVhXgAa+0gkAlMp5/X+UfoS44xOTHFwYoqDk8k3liemGJ2coj8xwSv7R3ilb4T4jJsFV9aVs76pavqxsbma9U1VrF5WUXDTSyanUjzxav90EOwdOIgZnL12GZeespwr3raS1ct0HeFwNPaRSB6LFdn0j/lcJcaTvNqXDojM8+6+Ee56tovBg5PT7UpixtqGStY3VbOxuYqTj6vltNX1HN9QuWh6Uo1NTrFj7yDbOwd4unOAR3b1MTA6SWlxEe/a1MQNF2/ioi3L53XaT+ZGoSCySFSXFXPqqrq39LjK9LZ6pS9BRzwdFq/ER9jdl+Chl+JMTKVPU9WUF3Pa6jretqqe01bXcdrqOlbVV0TeYyqVcl7ZP8L21wd4uvMA2zsH2Nk1PH0vyqr6Ci7a0sKlJy/nXZubqSrTz1aY9F9XZJF7o7dVA2cf3/CmbcmpFC/1JHhu7wDP7hnkub2DfP3h3UxOpX9wG6pKOb6xksaqMpprSqcHY2wKJoZqqiljZV05laUL+1MRHx7noZfi/PKlOL96Oc6B0fSRTnVZOri2vnsDZ6yp54y19bTUlC/oZ8vhKRREClhxrIiTj6vl5ONq+eDb0+vGk1O82D2cDok9g8FNgKNs7xygf2R81iHYVy+r4ISgW22me+2mluo5/6s9OZVie+cAD76YDoLn9g4C0FRdxoVbWjh3fSNnrK1nY3O1BkyMmEJBZIkpK45x2up6Tlv91hkGp1LOgdEJ+hLj9A2nnzv7R3kp6Dn18Mt906ejIB0WaxsqKY4VEbP0tZIis/RzsDw2OcXju/czNJYkVmSctbaev/idE/ntE5o5eWXtornOsVSEOUdzOfAQUBZ8zh3u/r9ntCkDbgXOBvYDH3T3V8OqSUQOL5Y1nwcr3ro9OZXitf5RXu5Jh8TLvQn2HBhlajw5Pdd5yp2plKfnQU85RUXG75yyggtObOGdm5s0HWaeC/NIYRy4yN0TZlYCPGxm97j7Y1ltPgEccPdNZnYN8A/AB0OsSUSOQXGsiI3N1WxsruayU2dJDVn0QuvM7GmJ4GVJ8Jh5tvIq4JZg+Q7gYou6K4SIyBIW6h0uZhYzs+1AL3C/uz8+o8kqoBPA3ZPAINAYZk0iInJooYaCu0+5+xnAauAcMzt1RpPZjgre0vfBzLaaWZuZtcXj8TBKFRERQg6FDHcfAB4ELpuxaQ+wBsDMioE6oH+W/be5e6u7tzY3N4dcrYjI0hVaKJhZs5nVB8sVwCXAzhnN7gT+MFi+Gvi5L7bBmERECkiYvY9WAreYWYx0+HzP3e8ysy8Abe5+J/B14Jtmtov0EcI1IdYjIiJHEFoouPuzwJmzrP981vIY8Pth1SAiIvNTWOPriojIMVl08ymYWRx47Rjeoo5019dc7j+ffebS9ljbNAF9c6wnnx3r32U+fGYhfB/n0u5I2wvhO5nv38fj3f3IPXXcfUk9gG253n8++8yl7bG2IX1NJ/K/i6j/LvPhMwvh+ziXdnPYvui/k4XwfXT3JXn66CcR7D+ffebSdqHaLHZR/BkX+jML4fs4l3b6Pi6Sz1x0p4/k2JlZm89hWj6RXNF3Mn8sxSMFgW1RFyAyg76TeUJHCiIiMk1HCiKsry8+AAAEZElEQVQiMk2hICIi0xQKIiIyTaEgb2Jm7zezr5nZf5jZpVHXI2JmG8zs62Z2R9S1LAUKhQJiZv9mZr1mtmPG+svM7EUz22Vmnz3ce7j7j939vwHXoalR5Rgt0Hdyt7t/ItxKJUO9jwqImb0bSAC3uvupwboY8BLwHtLzV/wGuBaIAX834y0+7u69wX7/DHzL3Z/KUflSgBb4O3mHu1+dq9qXqjCHzpYcc/eHzGzdjNXnALvcfTeAmX0HuMrd/w5438z3CObI/nvgHgWCHKuF+E5Kbun0UeGbngc7sCdYdyh/SnpCpKvN7PowC5Mla17fSTNrNLObgDPN7HNhF7fU6Uih8M1pHuzpDe5fAb4SXjki8/5O7gf0D5Qc0ZFC4ZueBzuwGtgXUS0ioO9kXlMoFL7fAJvNbL2ZlZKe8vTOiGuSpU3fyTymUCggZnY78ChwopntMbNPuHsS+DTwU6Cd9FzZz0dZpywd+k4uPuqSKiIi03SkICIi0xQKIiIyTaEgIiLTFAoiIjJNoSAiItMUCiIiMk2hIAXDzBI5/rybzezkHH/mn5tZZS4/U5YW3acgBcPMEu5evYDvVxzcaJUzwSi15u6pQ2x/FWh1975c1iVLh44UpKCZWbOZ/cDMfhM8zg/Wn2Nmvzazp4PnE4P115nZ983sJ8B9ZnaBmT1oZneY2U4z+1bww02wvjVYTpjZF83sGTN7zMyWB+s3Bq9/Y2ZfmO1oxszWmVm7mf0r8BSwxsy+amZtZva8mf1t0O4G4DjgF2b2i2DdpWb2qJk9FdS9YKEoS5S766FHQTyAxCzrvg28M1heC7QHy7VAcbB8CfCDYPk60gO2NQSvLwAGSQ/aVkR6yIbM+z1I+l/tkB7l878Ey/8I/K9g+S7g2mD5+kPUuA5IAedmrct8fiz4nNOC168CTcFyE/AQUBW8/ivg81H/PeixuB8aOlsK3SXAycE/7gFqzawGqANuMbPNpH/QS7L2ud/d+7NeP+HuewDMbDvpH/GHZ3zOBOkAAHiS9KxiAOcB7w+Wvw380yHqfM3dH8t6/QdmtpX08PYrgZOBZ2fsc26w/pHgz1dKOrREjppCQQpdEXCeux/MXmlm/wL8wt1/N5gZ7MGszSMz3mM8a3mK2f+/mXR3P0Kbw5n+TDNbD/xP4O3ufsDM/h0on2UfIx1g187zs0QOSdcUpNDdR3pETgDM7IxgsQ7YGyxfF+LnPwZ8IFi+Zo771JIOicHg2sTlWduGgZqs9z7fzDYBmFmlmZ1w7CXLUqZQkEJSGQzPnHl8BrgBaDWzZ83sBd6Ywesfgb8zs0dIn7cPy58DnzGzJ0ifBho80g7u/gzwNPA88G/AI1mbtwH3mNkv3D1OOtBuN7NnSYfEloUtX5YadUkVCVFwT8FBd3czu4b0Reeroq5L5FB0TUEkXGcDNwbdWAeAj0dcj8hh6UhBRESm6ZqCiIhMUyiIiMg0hYKIiExTKIiIyDSFgoiITFMoiIjItP8PIjWsQJgjxHkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "#training dataset\n",
    "training_set = torch.utils.data.DataLoader(\n",
    "torch.utils.data.ConcatDataset([\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms),\n",
    "    datasets.ImageFolder(args.data + '/train_images',\n",
    "                         transform=data_transforms_2)]), batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "#Model\n",
    "model = torchvision.models.resnet34(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 20)\n",
    "\n",
    "# We freeze the 4 next to last layers\n",
    "layer = 0\n",
    "for name, child in model.named_children():\n",
    "    layer += 1\n",
    "    if 5 < layer <= 9:\n",
    "        for name2, params in child.named_parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "\n",
    "#Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=args.momentum)\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion)\n",
    "lr_finder.range_test(train_loader=training_set,val_loader=None, end_lr=100, num_iter=100)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest lost is : 3.068930059111452 reached for LR = 0.08912509381337456\n"
     ]
    }
   ],
   "source": [
    "lrs = lr_finder.history[\"lr\"]#avoid the first small values\n",
    "losses = lr_finder.history[\"loss\"]\n",
    "\n",
    "print('The smallest lost is :',np.min(losses),'reached for LR =',lrs[np.argmin(losses)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Train Epoch: 1 [0/2164 (0%)]\tLoss: 3.593346\n",
      "Train Epoch: 1 [640/2164 (29%)]\tLoss: 9.133324\n",
      "Train Epoch: 1 [1280/2164 (59%)]\tLoss: 8.678043\n",
      "Train Epoch: 1 [1920/2164 (88%)]\tLoss: 4.248317\n",
      "Training set: Accuracy: 246/2164\n",
      "\n",
      "Validation set: Average loss: 0.1154, Accuracy: 14/103 (14%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/2164 (0%)]\tLoss: 4.618398\n",
      "Train Epoch: 2 [640/2164 (29%)]\tLoss: 4.128091\n",
      "Train Epoch: 2 [1280/2164 (59%)]\tLoss: 3.448338\n",
      "Train Epoch: 2 [1920/2164 (88%)]\tLoss: 3.882566\n",
      "Training set: Accuracy: 437/2164\n",
      "\n",
      "Validation set: Average loss: 0.1286, Accuracy: 12/103 (12%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/2164 (0%)]\tLoss: 5.651033\n",
      "Train Epoch: 3 [640/2164 (29%)]\tLoss: 3.715169\n",
      "Train Epoch: 3 [1280/2164 (59%)]\tLoss: 3.906302\n",
      "Train Epoch: 3 [1920/2164 (88%)]\tLoss: 3.544424\n",
      "Training set: Accuracy: 516/2164\n",
      "\n",
      "Validation set: Average loss: 0.1076, Accuracy: 15/103 (15%)\n",
      "Saved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 4 [0/2164 (0%)]\tLoss: 4.891955\n",
      "Train Epoch: 4 [640/2164 (29%)]\tLoss: 4.825559\n",
      "Train Epoch: 4 [1280/2164 (59%)]\tLoss: 4.476192\n",
      "Train Epoch: 4 [1920/2164 (88%)]\tLoss: 3.163960\n",
      "Training set: Accuracy: 523/2164\n",
      "\n",
      "Validation set: Average loss: 0.0765, Accuracy: 21/103 (20%)\n",
      "Saved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 5 [0/2164 (0%)]\tLoss: 4.110483\n",
      "Train Epoch: 5 [640/2164 (29%)]\tLoss: 3.299711\n",
      "Train Epoch: 5 [1280/2164 (59%)]\tLoss: 3.301000\n",
      "Train Epoch: 5 [1920/2164 (88%)]\tLoss: 2.669953\n",
      "Training set: Accuracy: 607/2164\n",
      "\n",
      "Validation set: Average loss: 0.0698, Accuracy: 23/103 (22%)\n",
      "Saved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 6 [0/2164 (0%)]\tLoss: 2.606431\n",
      "Train Epoch: 6 [640/2164 (29%)]\tLoss: 2.593322\n",
      "Train Epoch: 6 [1280/2164 (59%)]\tLoss: 3.030458\n",
      "Train Epoch: 6 [1920/2164 (88%)]\tLoss: 3.002261\n",
      "Training set: Accuracy: 710/2164\n",
      "\n",
      "Validation set: Average loss: 0.0581, Accuracy: 32/103 (31%)\n",
      "Saved model to experiment/model_6.pth. You can run `python evaluate.py --model experiment/model_6.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 7 [0/2164 (0%)]\tLoss: 2.634797\n",
      "Train Epoch: 7 [640/2164 (29%)]\tLoss: 3.237071\n",
      "Train Epoch: 7 [1280/2164 (59%)]\tLoss: 3.692200\n",
      "Train Epoch: 7 [1920/2164 (88%)]\tLoss: 3.747870\n",
      "Training set: Accuracy: 694/2164\n",
      "\n",
      "Validation set: Average loss: 0.0946, Accuracy: 22/103 (21%)\n",
      "Saved model to experiment/model_7.pth. You can run `python evaluate.py --model experiment/model_7.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 8 [0/2164 (0%)]\tLoss: 3.399578\n",
      "Train Epoch: 8 [640/2164 (29%)]\tLoss: 2.388195\n",
      "Train Epoch: 8 [1280/2164 (59%)]\tLoss: 2.537668\n",
      "Train Epoch: 8 [1920/2164 (88%)]\tLoss: 2.572138\n",
      "Training set: Accuracy: 754/2164\n",
      "\n",
      "Validation set: Average loss: 0.0762, Accuracy: 23/103 (22%)\n",
      "Saved model to experiment/model_8.pth. You can run `python evaluate.py --model experiment/model_8.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 9 [0/2164 (0%)]\tLoss: 2.160146\n",
      "Train Epoch: 9 [640/2164 (29%)]\tLoss: 2.096263\n",
      "Train Epoch: 9 [1280/2164 (59%)]\tLoss: 3.694446\n",
      "Train Epoch: 9 [1920/2164 (88%)]\tLoss: 2.400251\n",
      "Training set: Accuracy: 782/2164\n",
      "\n",
      "Validation set: Average loss: 0.0764, Accuracy: 27/103 (26%)\n",
      "Saved model to experiment/model_9.pth. You can run `python evaluate.py --model experiment/model_9.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 10 [0/2164 (0%)]\tLoss: 2.838834\n",
      "Train Epoch: 10 [640/2164 (29%)]\tLoss: 2.447930\n",
      "Train Epoch: 10 [1280/2164 (59%)]\tLoss: 3.077616\n",
      "Train Epoch: 10 [1920/2164 (88%)]\tLoss: 2.782120\n",
      "Training set: Accuracy: 816/2164\n",
      "\n",
      "Validation set: Average loss: 0.0614, Accuracy: 36/103 (35%)\n",
      "Saved model to experiment/model_10.pth. You can run `python evaluate.py --model experiment/model_10.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 11 [0/2164 (0%)]\tLoss: 2.248729\n",
      "Train Epoch: 11 [640/2164 (29%)]\tLoss: 3.099881\n",
      "Train Epoch: 11 [1280/2164 (59%)]\tLoss: 2.351916\n",
      "Train Epoch: 11 [1920/2164 (88%)]\tLoss: 2.889784\n",
      "Training set: Accuracy: 827/2164\n",
      "\n",
      "Validation set: Average loss: 0.0794, Accuracy: 34/103 (33%)\n",
      "Saved model to experiment/model_11.pth. You can run `python evaluate.py --model experiment/model_11.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 12 [0/2164 (0%)]\tLoss: 2.241345\n",
      "Train Epoch: 12 [640/2164 (29%)]\tLoss: 2.079332\n",
      "Train Epoch: 12 [1280/2164 (59%)]\tLoss: 2.220893\n",
      "Train Epoch: 12 [1920/2164 (88%)]\tLoss: 1.790986\n",
      "Training set: Accuracy: 927/2164\n",
      "\n",
      "Validation set: Average loss: 0.0681, Accuracy: 26/103 (25%)\n",
      "Saved model to experiment/model_12.pth. You can run `python evaluate.py --model experiment/model_12.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 13 [0/2164 (0%)]\tLoss: 1.872918\n",
      "Train Epoch: 13 [640/2164 (29%)]\tLoss: 1.984320\n",
      "Train Epoch: 13 [1280/2164 (59%)]\tLoss: 1.640437\n",
      "Train Epoch: 13 [1920/2164 (88%)]\tLoss: 2.405610\n",
      "Training set: Accuracy: 963/2164\n",
      "\n",
      "Validation set: Average loss: 0.0672, Accuracy: 29/103 (28%)\n",
      "Saved model to experiment/model_13.pth. You can run `python evaluate.py --model experiment/model_13.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 14 [0/2164 (0%)]\tLoss: 2.544924\n",
      "Train Epoch: 14 [640/2164 (29%)]\tLoss: 1.950360\n",
      "Train Epoch: 14 [1280/2164 (59%)]\tLoss: 2.484713\n",
      "Train Epoch: 14 [1920/2164 (88%)]\tLoss: 2.889082\n",
      "Training set: Accuracy: 925/2164\n",
      "\n",
      "Validation set: Average loss: 0.0933, Accuracy: 22/103 (21%)\n",
      "Saved model to experiment/model_14.pth. You can run `python evaluate.py --model experiment/model_14.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 15 [0/2164 (0%)]\tLoss: 2.185150\n",
      "Train Epoch: 15 [640/2164 (29%)]\tLoss: 1.604303\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-c42c5c657c19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/model_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pth'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Kaggle\\main.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alixa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alixa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "%run main.py --epochs=20 --cgpu='CPU' --lr=0.089 --augmented=True\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
    "\n",
    "print('CPU- Time of execution :',time.time()-start,'s')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea : Reloading best previous state and retraining on difficult pictures\n",
    "#### (pictures where the error was higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"layer1.0.conv3.weight\", \"layer1.0.bn3.running_var\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.bias\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.running_var\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.bias\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.running_var\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.bias\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.running_var\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.bias\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.running_var\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.bias\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.running_var\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.bias\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.running_var\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.bias\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.running_var\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.bias\", \"layer2.4.conv1.weight\", \"layer2.4.bn1.running_var\", \"layer2.4.bn1.weight\", \"layer2.4.bn1.running_mean\", \"layer2.4.bn1.bias\", \"layer2.4.conv2.weight\", \"layer2.4.bn2.running_var\", \"layer2.4.bn2.weight\", \"layer2.4.bn2.running_mean\", \"layer2.4.bn2.bias\", \"layer2.4.conv3.weight\", \"layer2.4.bn3.running_var\", \"layer2.4.bn3.weight\", \"layer2.4.bn3.running_mean\", \"layer2.4.bn3.bias\", \"layer2.5.conv1.weight\", \"layer2.5.bn1.running_var\", \"layer2.5.bn1.weight\", \"layer2.5.bn1.running_mean\", \"layer2.5.bn1.bias\", \"layer2.5.conv2.weight\", \"layer2.5.bn2.running_var\", \"layer2.5.bn2.weight\", \"layer2.5.bn2.running_mean\", \"layer2.5.bn2.bias\", \"layer2.5.conv3.weight\", \"layer2.5.bn3.running_var\", \"layer2.5.bn3.weight\", \"layer2.5.bn3.running_mean\", \"layer2.5.bn3.bias\", \"layer2.6.conv1.weight\", \"layer2.6.bn1.running_var\", \"layer2.6.bn1.weight\", \"layer2.6.bn1.running_mean\", \"layer2.6.bn1.bias\", \"layer2.6.conv2.weight\", \"layer2.6.bn2.running_var\", \"layer2.6.bn2.weight\", \"layer2.6.bn2.running_mean\", \"layer2.6.bn2.bias\", \"layer2.6.conv3.weight\", \"layer2.6.bn3.running_var\", \"layer2.6.bn3.weight\", \"layer2.6.bn3.running_mean\", \"layer2.6.bn3.bias\", \"layer2.7.conv1.weight\", \"layer2.7.bn1.running_var\", \"layer2.7.bn1.weight\", \"layer2.7.bn1.running_mean\", \"layer2.7.bn1.bias\", \"layer2.7.conv2.weight\", \"layer2.7.bn2.running_var\", \"layer2.7.bn2.weight\", \"layer2.7.bn2.running_mean\", \"layer2.7.bn2.bias\", \"layer2.7.conv3.weight\", \"layer2.7.bn3.running_var\", \"layer2.7.bn3.weight\", \"layer2.7.bn3.running_mean\", \"layer2.7.bn3.bias\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.running_var\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.bias\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.running_var\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.bias\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.running_var\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.bias\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.running_var\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.bias\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.running_var\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.bias\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.running_var\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.bias\", \"layer3.6.conv1.weight\", \"layer3.6.bn1.running_var\", \"layer3.6.bn1.weight\", \"layer3.6.bn1.running_mean\", \"layer3.6.bn1.bias\", \"layer3.6.conv2.weight\", \"layer3.6.bn2.running_var\", \"layer3.6.bn2.weight\", \"layer3.6.bn2.running_mean\", \"layer3.6.bn2.bias\", \"layer3.6.conv3.weight\", \"layer3.6.bn3.running_var\", \"layer3.6.bn3.weight\", \"layer3.6.bn3.running_mean\", \"layer3.6.bn3.bias\", \"layer3.7.conv1.weight\", \"layer3.7.bn1.running_var\", \"layer3.7.bn1.weight\", \"layer3.7.bn1.running_mean\", \"layer3.7.bn1.bias\", \"layer3.7.conv2.weight\", \"layer3.7.bn2.running_var\", \"layer3.7.bn2.weight\", \"layer3.7.bn2.running_mean\", \"layer3.7.bn2.bias\", \"layer3.7.conv3.weight\", \"layer3.7.bn3.running_var\", \"layer3.7.bn3.weight\", \"layer3.7.bn3.running_mean\", \"layer3.7.bn3.bias\", \"layer3.8.conv1.weight\", \"layer3.8.bn1.running_var\", \"layer3.8.bn1.weight\", \"layer3.8.bn1.running_mean\", \"layer3.8.bn1.bias\", \"layer3.8.conv2.weight\", \"layer3.8.bn2.running_var\", \"layer3.8.bn2.weight\", \"layer3.8.bn2.running_mean\", \"layer3.8.bn2.bias\", \"layer3.8.conv3.weight\", \"layer3.8.bn3.running_var\", \"layer3.8.bn3.weight\", \"layer3.8.bn3.running_mean\", \"layer3.8.bn3.bias\", \"layer3.9.conv1.weight\", \"layer3.9.bn1.running_var\", \"layer3.9.bn1.weight\", \"layer3.9.bn1.running_mean\", \"layer3.9.bn1.bias\", \"layer3.9.conv2.weight\", \"layer3.9.bn2.running_var\", \"layer3.9.bn2.weight\", \"layer3.9.bn2.running_mean\", \"layer3.9.bn2.bias\", \"layer3.9.conv3.weight\", \"layer3.9.bn3.running_var\", \"layer3.9.bn3.weight\", \"layer3.9.bn3.running_mean\", \"layer3.9.bn3.bias\", \"layer3.10.conv1.weight\", \"layer3.10.bn1.running_var\", \"layer3.10.bn1.weight\", \"layer3.10.bn1.running_mean\", \"layer3.10.bn1.bias\", \"layer3.10.conv2.weight\", \"layer3.10.bn2.running_var\", \"layer3.10.bn2.weight\", \"layer3.10.bn2.running_mean\", \"layer3.10.bn2.bias\", \"layer3.10.conv3.weight\", \"layer3.10.bn3.running_var\", \"layer3.10.bn3.weight\", \"layer3.10.bn3.running_mean\", \"layer3.10.bn3.bias\", \"layer3.11.conv1.weight\", \"layer3.11.bn1.running_var\", \"layer3.11.bn1.weight\", \"layer3.11.bn1.running_mean\", \"layer3.11.bn1.bias\", \"layer3.11.conv2.weight\", \"layer3.11.bn2.running_var\", \"layer3.11.bn2.weight\", \"layer3.11.bn2.running_mean\", \"layer3.11.bn2.bias\", \"layer3.11.conv3.weight\", \"layer3.11.bn3.running_var\", \"layer3.11.bn3.weight\", \"layer3.11.bn3.running_mean\", \"layer3.11.bn3.bias\", \"layer3.12.conv1.weight\", \"layer3.12.bn1.running_var\", \"layer3.12.bn1.weight\", \"layer3.12.bn1.running_mean\", \"layer3.12.bn1.bias\", \"layer3.12.conv2.weight\", \"layer3.12.bn2.running_var\", \"layer3.12.bn2.weight\", \"layer3.12.bn2.running_mean\", \"layer3.12.bn2.bias\", \"layer3.12.conv3.weight\", \"layer3.12.bn3.running_var\", \"layer3.12.bn3.weight\", \"layer3.12.bn3.running_mean\", \"layer3.12.bn3.bias\", \"layer3.13.conv1.weight\", \"layer3.13.bn1.running_var\", \"layer3.13.bn1.weight\", \"layer3.13.bn1.running_mean\", \"layer3.13.bn1.bias\", \"layer3.13.conv2.weight\", \"layer3.13.bn2.running_var\", \"layer3.13.bn2.weight\", \"layer3.13.bn2.running_mean\", \"layer3.13.bn2.bias\", \"layer3.13.conv3.weight\", \"layer3.13.bn3.running_var\", \"layer3.13.bn3.weight\", \"layer3.13.bn3.running_mean\", \"layer3.13.bn3.bias\", \"layer3.14.conv1.weight\", \"layer3.14.bn1.running_var\", \"layer3.14.bn1.weight\", \"layer3.14.bn1.running_mean\", \"layer3.14.bn1.bias\", \"layer3.14.conv2.weight\", \"layer3.14.bn2.running_var\", \"layer3.14.bn2.weight\", \"layer3.14.bn2.running_mean\", \"layer3.14.bn2.bias\", \"layer3.14.conv3.weight\", \"layer3.14.bn3.running_var\", \"layer3.14.bn3.weight\", \"layer3.14.bn3.running_mean\", \"layer3.14.bn3.bias\", \"layer3.15.conv1.weight\", \"layer3.15.bn1.running_var\", \"layer3.15.bn1.weight\", \"layer3.15.bn1.running_mean\", \"layer3.15.bn1.bias\", \"layer3.15.conv2.weight\", \"layer3.15.bn2.running_var\", \"layer3.15.bn2.weight\", \"layer3.15.bn2.running_mean\", \"layer3.15.bn2.bias\", \"layer3.15.conv3.weight\", \"layer3.15.bn3.running_var\", \"layer3.15.bn3.weight\", \"layer3.15.bn3.running_mean\", \"layer3.15.bn3.bias\", \"layer3.16.conv1.weight\", \"layer3.16.bn1.running_var\", \"layer3.16.bn1.weight\", \"layer3.16.bn1.running_mean\", \"layer3.16.bn1.bias\", \"layer3.16.conv2.weight\", \"layer3.16.bn2.running_var\", \"layer3.16.bn2.weight\", \"layer3.16.bn2.running_mean\", \"layer3.16.bn2.bias\", \"layer3.16.conv3.weight\", \"layer3.16.bn3.running_var\", \"layer3.16.bn3.weight\", \"layer3.16.bn3.running_mean\", \"layer3.16.bn3.bias\", \"layer3.17.conv1.weight\", \"layer3.17.bn1.running_var\", \"layer3.17.bn1.weight\", \"layer3.17.bn1.running_mean\", \"layer3.17.bn1.bias\", \"layer3.17.conv2.weight\", \"layer3.17.bn2.running_var\", \"layer3.17.bn2.weight\", \"layer3.17.bn2.running_mean\", \"layer3.17.bn2.bias\", \"layer3.17.conv3.weight\", \"layer3.17.bn3.running_var\", \"layer3.17.bn3.weight\", \"layer3.17.bn3.running_mean\", \"layer3.17.bn3.bias\", \"layer3.18.conv1.weight\", \"layer3.18.bn1.running_var\", \"layer3.18.bn1.weight\", \"layer3.18.bn1.running_mean\", \"layer3.18.bn1.bias\", \"layer3.18.conv2.weight\", \"layer3.18.bn2.running_var\", \"layer3.18.bn2.weight\", \"layer3.18.bn2.running_mean\", \"layer3.18.bn2.bias\", \"layer3.18.conv3.weight\", \"layer3.18.bn3.running_var\", \"layer3.18.bn3.weight\", \"layer3.18.bn3.running_mean\", \"layer3.18.bn3.bias\", \"layer3.19.conv1.weight\", \"layer3.19.bn1.running_var\", \"layer3.19.bn1.weight\", \"layer3.19.bn1.running_mean\", \"layer3.19.bn1.bias\", \"layer3.19.conv2.weight\", \"layer3.19.bn2.running_var\", \"layer3.19.bn2.weight\", \"layer3.19.bn2.running_mean\", \"layer3.19.bn2.bias\", \"layer3.19.conv3.weight\", \"layer3.19.bn3.running_var\", \"layer3.19.bn3.weight\", \"layer3.19.bn3.running_mean\", \"layer3.19.bn3.bias\", \"layer3.20.conv1.weight\", \"layer3.20.bn1.running_var\", \"layer3.20.bn1.weight\", \"layer3.20.bn1.running_mean\", \"layer3.20.bn1.bias\", \"layer3.20.conv2.weight\", \"layer3.20.bn2.running_var\", \"layer3.20.bn2.weight\", \"layer3.20.bn2.running_mean\", \"layer3.20.bn2.bias\", \"layer3.20.conv3.weight\", \"layer3.20.bn3.running_var\", \"layer3.20.bn3.weight\", \"layer3.20.bn3.running_mean\", \"layer3.20.bn3.bias\", \"layer3.21.conv1.weight\", \"layer3.21.bn1.running_var\", \"layer3.21.bn1.weight\", \"layer3.21.bn1.running_mean\", \"layer3.21.bn1.bias\", \"layer3.21.conv2.weight\", \"layer3.21.bn2.running_var\", \"layer3.21.bn2.weight\", \"layer3.21.bn2.running_mean\", \"layer3.21.bn2.bias\", \"layer3.21.conv3.weight\", \"layer3.21.bn3.running_var\", \"layer3.21.bn3.weight\", \"layer3.21.bn3.running_mean\", \"layer3.21.bn3.bias\", \"layer3.22.conv1.weight\", \"layer3.22.bn1.running_var\", \"layer3.22.bn1.weight\", \"layer3.22.bn1.running_mean\", \"layer3.22.bn1.bias\", \"layer3.22.conv2.weight\", \"layer3.22.bn2.running_var\", \"layer3.22.bn2.weight\", \"layer3.22.bn2.running_mean\", \"layer3.22.bn2.bias\", \"layer3.22.conv3.weight\", \"layer3.22.bn3.running_var\", \"layer3.22.bn3.weight\", \"layer3.22.bn3.running_mean\", \"layer3.22.bn3.bias\", \"layer3.23.conv1.weight\", \"layer3.23.bn1.running_var\", \"layer3.23.bn1.weight\", \"layer3.23.bn1.running_mean\", \"layer3.23.bn1.bias\", \"layer3.23.conv2.weight\", \"layer3.23.bn2.running_var\", \"layer3.23.bn2.weight\", \"layer3.23.bn2.running_mean\", \"layer3.23.bn2.bias\", \"layer3.23.conv3.weight\", \"layer3.23.bn3.running_var\", \"layer3.23.bn3.weight\", \"layer3.23.bn3.running_mean\", \"layer3.23.bn3.bias\", \"layer3.24.conv1.weight\", \"layer3.24.bn1.running_var\", \"layer3.24.bn1.weight\", \"layer3.24.bn1.running_mean\", \"layer3.24.bn1.bias\", \"layer3.24.conv2.weight\", \"layer3.24.bn2.running_var\", \"layer3.24.bn2.weight\", \"layer3.24.bn2.running_mean\", \"layer3.24.bn2.bias\", \"layer3.24.conv3.weight\", \"layer3.24.bn3.running_var\", \"layer3.24.bn3.weight\", \"layer3.24.bn3.running_mean\", \"layer3.24.bn3.bias\", \"layer3.25.conv1.weight\", \"layer3.25.bn1.running_var\", \"layer3.25.bn1.weight\", \"layer3.25.bn1.running_mean\", \"layer3.25.bn1.bias\", \"layer3.25.conv2.weight\", \"layer3.25.bn2.running_var\", \"layer3.25.bn2.weight\", \"layer3.25.bn2.running_mean\", \"layer3.25.bn2.bias\", \"layer3.25.conv3.weight\", \"layer3.25.bn3.running_var\", \"layer3.25.bn3.weight\", \"layer3.25.bn3.running_mean\", \"layer3.25.bn3.bias\", \"layer3.26.conv1.weight\", \"layer3.26.bn1.running_var\", \"layer3.26.bn1.weight\", \"layer3.26.bn1.running_mean\", \"layer3.26.bn1.bias\", \"layer3.26.conv2.weight\", \"layer3.26.bn2.running_var\", \"layer3.26.bn2.weight\", \"layer3.26.bn2.running_mean\", \"layer3.26.bn2.bias\", \"layer3.26.conv3.weight\", \"layer3.26.bn3.running_var\", \"layer3.26.bn3.weight\", \"layer3.26.bn3.running_mean\", \"layer3.26.bn3.bias\", \"layer3.27.conv1.weight\", \"layer3.27.bn1.running_var\", \"layer3.27.bn1.weight\", \"layer3.27.bn1.running_mean\", \"layer3.27.bn1.bias\", \"layer3.27.conv2.weight\", \"layer3.27.bn2.running_var\", \"layer3.27.bn2.weight\", \"layer3.27.bn2.running_mean\", \"layer3.27.bn2.bias\", \"layer3.27.conv3.weight\", \"layer3.27.bn3.running_var\", \"layer3.27.bn3.weight\", \"layer3.27.bn3.running_mean\", \"layer3.27.bn3.bias\", \"layer3.28.conv1.weight\", \"layer3.28.bn1.running_var\", \"layer3.28.bn1.weight\", \"layer3.28.bn1.running_mean\", \"layer3.28.bn1.bias\", \"layer3.28.conv2.weight\", \"layer3.28.bn2.running_var\", \"layer3.28.bn2.weight\", \"layer3.28.bn2.running_mean\", \"layer3.28.bn2.bias\", \"layer3.28.conv3.weight\", \"layer3.28.bn3.running_var\", \"layer3.28.bn3.weight\", \"layer3.28.bn3.running_mean\", \"layer3.28.bn3.bias\", \"layer3.29.conv1.weight\", \"layer3.29.bn1.running_var\", \"layer3.29.bn1.weight\", \"layer3.29.bn1.running_mean\", \"layer3.29.bn1.bias\", \"layer3.29.conv2.weight\", \"layer3.29.bn2.running_var\", \"layer3.29.bn2.weight\", \"layer3.29.bn2.running_mean\", \"layer3.29.bn2.bias\", \"layer3.29.conv3.weight\", \"layer3.29.bn3.running_var\", \"layer3.29.bn3.weight\", \"layer3.29.bn3.running_mean\", \"layer3.29.bn3.bias\", \"layer3.30.conv1.weight\", \"layer3.30.bn1.running_var\", \"layer3.30.bn1.weight\", \"layer3.30.bn1.running_mean\", \"layer3.30.bn1.bias\", \"layer3.30.conv2.weight\", \"layer3.30.bn2.running_var\", \"layer3.30.bn2.weight\", \"layer3.30.bn2.running_mean\", \"layer3.30.bn2.bias\", \"layer3.30.conv3.weight\", \"layer3.30.bn3.running_var\", \"layer3.30.bn3.weight\", \"layer3.30.bn3.running_mean\", \"layer3.30.bn3.bias\", \"layer3.31.conv1.weight\", \"layer3.31.bn1.running_var\", \"layer3.31.bn1.weight\", \"layer3.31.bn1.running_mean\", \"layer3.31.bn1.bias\", \"layer3.31.conv2.weight\", \"layer3.31.bn2.running_var\", \"layer3.31.bn2.weight\", \"layer3.31.bn2.running_mean\", \"layer3.31.bn2.bias\", \"layer3.31.conv3.weight\", \"layer3.31.bn3.running_var\", \"layer3.31.bn3.weight\", \"layer3.31.bn3.running_mean\", \"layer3.31.bn3.bias\", \"layer3.32.conv1.weight\", \"layer3.32.bn1.running_var\", \"layer3.32.bn1.weight\", \"layer3.32.bn1.running_mean\", \"layer3.32.bn1.bias\", \"layer3.32.conv2.weight\", \"layer3.32.bn2.running_var\", \"layer3.32.bn2.weight\", \"layer3.32.bn2.running_mean\", \"layer3.32.bn2.bias\", \"layer3.32.conv3.weight\", \"layer3.32.bn3.running_var\", \"layer3.32.bn3.weight\", \"layer3.32.bn3.running_mean\", \"layer3.32.bn3.bias\", \"layer3.33.conv1.weight\", \"layer3.33.bn1.running_var\", \"layer3.33.bn1.weight\", \"layer3.33.bn1.running_mean\", \"layer3.33.bn1.bias\", \"layer3.33.conv2.weight\", \"layer3.33.bn2.running_var\", \"layer3.33.bn2.weight\", \"layer3.33.bn2.running_mean\", \"layer3.33.bn2.bias\", \"layer3.33.conv3.weight\", \"layer3.33.bn3.running_var\", \"layer3.33.bn3.weight\", \"layer3.33.bn3.running_mean\", \"layer3.33.bn3.bias\", \"layer3.34.conv1.weight\", \"layer3.34.bn1.running_var\", \"layer3.34.bn1.weight\", \"layer3.34.bn1.running_mean\", \"layer3.34.bn1.bias\", \"layer3.34.conv2.weight\", \"layer3.34.bn2.running_var\", \"layer3.34.bn2.weight\", \"layer3.34.bn2.running_mean\", \"layer3.34.bn2.bias\", \"layer3.34.conv3.weight\", \"layer3.34.bn3.running_var\", \"layer3.34.bn3.weight\", \"layer3.34.bn3.running_mean\", \"layer3.34.bn3.bias\", \"layer3.35.conv1.weight\", \"layer3.35.bn1.running_var\", \"layer3.35.bn1.weight\", \"layer3.35.bn1.running_mean\", \"layer3.35.bn1.bias\", \"layer3.35.conv2.weight\", \"layer3.35.bn2.running_var\", \"layer3.35.bn2.weight\", \"layer3.35.bn2.running_mean\", \"layer3.35.bn2.bias\", \"layer3.35.conv3.weight\", \"layer3.35.bn3.running_var\", \"layer3.35.bn3.weight\", \"layer3.35.bn3.running_mean\", \"layer3.35.bn3.bias\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.running_var\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.bias\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.running_var\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.bias\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.running_var\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.bias\". \n\tsize mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([20, 512]) from checkpoint, the shape in current model is torch.Size([20, 2048]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\Desktop\\Kaggle\\main.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[0mset_parameter_requires_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_extracting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'experiment/model_6.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alixa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    837\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 839\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    840\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"layer1.0.conv3.weight\", \"layer1.0.bn3.running_var\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.bias\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.running_var\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.bias\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.running_var\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.bias\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.running_var\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.bias\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.running_var\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.bias\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.running_var\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.bias\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.running_var\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.bias\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.running_var\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.bias\", \"layer2.4.conv1.weight\", \"layer2.4.bn1.running_var\", \"layer2.4.bn1.weight\", \"layer2.4.bn1.running_mean\", \"layer2.4.bn1.bias\", \"layer2.4.conv2.weight\", \"layer2.4.bn2.running_var\", \"layer2.4.bn2.weight\", \"layer2.4.bn2.running_mean\", \"layer2.4.bn2.bias\", \"layer2.4.conv3.weight\", \"layer2.4.bn3.running_var\", \"layer2.4.bn3.weight\", \"layer2.4.bn3.running_mean\", \"layer2.4.bn3.bias\", \"layer2.5.conv1.weight\", \"layer2.5.bn1.running_var\", \"layer2.5.bn1.weight\", \"layer2.5.bn1.running_mean\", \"layer2.5.bn1.bias\", \"layer2.5.conv2.weight\", \"layer2.5.bn2.running_var\", \"layer2.5.bn2.weight\", \"layer2.5.bn2.running_mean\", \"layer2.5.bn2.bias\", \"layer2.5.conv3.weight\", \"layer2.5.bn3.running_var\", \"layer2.5.bn3.weight\", \"layer2.5.bn3.running_mean\", \"layer2.5.bn3.bias\", \"layer2.6.conv1.weight\", \"layer2.6.bn1.running_var\", \"layer2.6.bn1.weight\", \"layer2.6.bn1.running_mean\", \"layer2.6.bn1.bias\", \"layer2.6.conv2.weight\", \"layer2.6.bn2.running_var\", \"layer2.6.bn2.weight\", \"layer2.6.bn2.running_mean\", \"layer2.6.bn2.bias\", \"layer2.6.conv3.weight\", \"layer2.6.bn3.running_var\", \"layer2.6.bn3.weight\", \"layer2.6.bn3.running_mean\", \"layer2.6.bn3.bias\", \"layer2.7.conv1.weight\", \"layer2.7.bn1.running_var\", \"layer2.7.bn1.weight\", \"layer2.7.bn1.running_mean\", \"layer2.7.bn1.bias\", \"layer2.7.conv2.weight\", \"layer2.7.bn2.running_var\", \"layer2.7.bn2.weight\", \"layer2.7.bn2.running_mean\", \"layer2.7.bn2.bias\", \"layer2.7.conv3.weight\", \"layer2.7.bn3.running_var\", \"layer2.7.bn3.weight\", \"layer2.7.bn3.running_mean\", \"layer2.7.bn3.bias\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.running_var\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.bias\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.running_var\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.bias\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.running_var\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.bias\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.running_var\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.bias\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.running_var\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.bias\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.running_var\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.bias\", \"layer3.6.conv1.weight\", \"layer3.6.bn1.running_var\", \"layer3.6.bn1.weight\", \"layer3.6.bn1.running_mean\", \"layer3.6.bn1.bias\", \"layer3.6.conv2.weight\", \"layer3.6.bn2.running_var\", \"layer3.6.bn2.weight\", \"layer3.6.bn2.running_mean\", \"layer3.6.bn2.bias\", \"layer3.6.conv3.weight\", \"layer3.6.bn3.running_var\", \"layer3.6.bn3.weight\", \"layer3.6.bn3.running_mean\", \"layer3.6.bn3.bias\", \"layer3.7.conv1.weight\", \"layer3.7.bn1.running_var\", \"layer3.7.bn1.weight\", \"layer3.7.bn1.running_mean\", \"layer3.7.bn1.bias\", \"layer3.7.conv2.weight\", \"layer3.7.bn2.running_var\", \"layer3.7.bn2.weight\", \"layer3.7.bn2.running_mean\", \"layer3.7.bn2.bias\", \"layer3.7.conv3.weight\", \"layer3.7.bn3.running_var\", \"layer3.7.bn3.weight\", \"layer3.7.bn3.running_mean\", \"layer3.7.bn3.bias\", \"layer3.8.conv1.weight\", \"layer3.8.bn1.running_var\", \"layer3.8.bn1.weight\", \"layer3.8.bn1.running_mean\", \"layer3.8.bn1.bias\", \"layer3.8.conv2.weight\", \"layer3.8.bn2.running_var\", \"layer3.8.bn2.weight\", \"layer3.8.bn2.running_mean\", \"layer3.8.bn2.bias\", \"layer3.8.conv3.weight\", \"layer3.8.bn3.running_var\", \"layer3.8.bn3.weight\", \"layer3.8.bn3.running_mean\", \"layer3.8.bn3.bias\", \"layer3.9.conv1.weight\", \"layer3.9.bn1.running_var\", \"layer3.9.bn1.weight\", \"layer3.9.bn1.running_mean\", \"layer3.9.bn1.bias\", \"layer3.9.conv2.weight\", \"layer3.9.bn2.running_var\", \"layer3.9.bn2.weight\", \"layer3.9.bn2.running_mean\", \"layer3.9.bn2.bias\", \"layer3.9.conv3.weight\", \"layer3.9.bn3.running_var\", \"layer3.9.bn3.weight\", \"layer3.9.bn3.running_mean\", \"layer3.9.bn3.bias\", \"layer3.10.conv1.weight\", \"layer3.10.bn1.running_var\", \"layer3.10.bn1.weight\", \"layer3.10.bn1.running_mean\", \"layer3.10.bn1.bias\", \"layer3.10.conv2.weight\", \"layer3.10.bn2.running_var\", \"layer3.10.bn2.weight\", \"layer3.10.bn2.running_mean\", \"layer3.10.bn2.bias\", \"layer3.10.conv3.weight\", \"layer3.10.bn3.running_var\", \"layer3.10.bn3.weight\", \"layer3.10.bn3.running_mean\", \"layer3.10.bn3.bias\", \"layer3.11.conv1.weight\", \"layer3.11.bn1.running_var\", \"layer3.11.bn1.weight\", \"layer3.11.bn1.running_mean\", \"layer3.11.bn1.bias\", \"layer3.11.conv2.weight\", \"layer3.11.bn2.running_var\", \"layer3.11.bn2.weight\", \"layer3.11.bn2.running_mean\", \"layer3.11.bn2.bias\", \"layer3.11.conv3.weight\", \"layer3.11.bn3.running_var\", \"layer3.11.bn3.weight\", \"layer3.11.bn3.running_mean\", \"layer3.11.bn3.bias\", \"layer3.12.conv1.weight\", \"layer3.12.bn1.running_var\", \"layer3.12.bn1.weight\", \"layer3.12.bn1.running_mean\", \"layer3.12.bn1.bias\", \"layer3.12.conv2.weight\", \"layer3.12.bn2.running_var\", \"layer3.12.bn2.weight\", \"layer3.12.bn2.running_mean\", \"layer3.12.bn2.bias\", \"layer3.12.conv3.weight\", \"layer3.12.bn3.running_var\", \"layer3.12.bn3.weight\", \"layer3.12.bn3.running_mean\", \"layer3.12.bn3.bias\", \"layer3.13.conv1.weight\", \"layer3.13.bn1.running_var\", \"layer3.13.bn1.weight\", \"layer3.13.bn1.running_mean\", \"layer3.13.bn1.bias\", \"layer3.13.conv2.weight\", \"layer3.13.bn2.running_var\", \"layer3.13.bn2.weight\", \"layer3.13.bn2.running_mean\", \"layer3.13.bn2.bias\", \"layer3.13.conv3.weight\", \"layer3.13.bn3.running_var\", \"layer3.13.bn3.weight\", \"layer3.13.bn3.running_mean\", \"layer3.13.bn3.bias\", \"layer3.14.conv1.weight\", \"layer3.14.bn1.running_var\", \"layer3.14.bn1.weight\", \"layer3.14.bn1.running_mean\", \"layer3.14.bn1.bias\", \"layer3.14.conv2.weight\", \"layer3.14.bn2.running_var\", \"layer3.14.bn2.weight\", \"layer3.14.bn2.running_mean\", \"layer3.14.bn2.bias\", \"layer3.14.conv3.weight\", \"layer3.14.bn3.running_var\", \"layer3.14.bn3.weight\", \"layer3.14.bn3.running_mean\", \"layer3.14.bn3.bias\", \"layer3.15.conv1.weight\", \"layer3.15.bn1.running_var\", \"layer3.15.bn1.weight\", \"layer3.15.bn1.running_mean\", \"layer3.15.bn1.bias\", \"layer3.15.conv2.weight\", \"layer3.15.bn2.running_var\", \"layer3.15.bn2.weight\", \"layer3.15.bn2.running_mean\", \"layer3.15.bn2.bias\", \"layer3.15.conv3.weight\", \"layer3.15.bn3.running_var\", \"layer3.15.bn3.weight\", \"layer3.15.bn3.running_mean\", \"layer3.15.bn3.bias\", \"layer3.16.conv1.weight\", \"layer3.16.bn1.running_var\", \"layer3.16.bn1.weight\", \"layer3.16.bn1.running_mean\", \"layer3.16.bn1.bias\", \"layer3.16.conv2.weight\", \"layer3.16.bn2.running_var\", \"layer3.16.bn2.weight\", \"layer3.16.bn2.running_mean\", \"layer3.16.bn2.bias\", \"layer3.16.conv3.weight\", \"layer3.16.bn3.running_var\", \"layer3.16.bn3.weight\", \"layer3.16.bn3.running_mean\", \"layer3.16.bn3.bias\", \"layer3.17.conv1.weight\", \"layer3.17.bn1.running_var\", \"layer3.17.bn1.weight\", \"layer3.17.bn1.running_mean\", \"layer3.17.bn1.bias\", \"layer3.17.conv2.weight\", \"layer3.17.bn2.running_var\", \"layer3.17.bn2.weight\", \"layer3.17.bn2.running_mean\", \"layer3.17.bn2.bias\", \"layer3.17.conv3.weight\", \"layer3.17.bn3.running_var\", \"layer3.17.bn3.weight\", \"layer3.17.bn3.running_mean\", \"layer3.17.bn3.bias\", \"layer3.18.conv1.weight\", \"layer3.18.bn1.running_var\", \"layer3.18.bn1.weight\", \"layer3.18.bn1.running_mean\", \"layer3.18.bn1.bias\", \"layer3.18.conv2.weight\", \"layer3.18.bn2.running_var\", \"layer3.18.bn2.weight\", \"layer3.18.bn2.running_mean\", \"layer3.18.bn2.bias\", \"layer3.18.conv3.weight\", \"layer3.18.bn3.running_var\", \"layer3.18.bn3.weight\", \"layer3.18.bn3.running_mean\", \"layer3.18.bn3.bias\", \"layer3.19.conv1.weight\", \"layer3.19.bn1.running_var\", \"layer3.19.bn1.weight\", \"layer3.19.bn1.running_mean\", \"layer3.19.bn1.bias\", \"layer3.19.conv2.weight\", \"layer3.19.bn2.running_var\", \"layer3.19.bn2.weight\", \"layer3.19.bn2.running_mean\", \"layer3.19.bn2.bias\", \"layer3.19.conv3.weight\", \"layer3.19.bn3.running_var\", \"layer3.19.bn3.weight\", \"layer3.19.bn3.running_mean\", \"layer3.19.bn3.bias\", \"layer3.20.conv1.weight\", \"layer3.20.bn1.running_var\", \"layer3.20.bn1.weight\", \"layer3.20.bn1.running_mean\", \"layer3.20.bn1.bias\", \"layer3.20.conv2.weight\", \"layer3.20.bn2.running_var\", \"layer3.20.bn2.weight\", \"layer3.20.bn2.running_mean\", \"layer3.20.bn2.bias\", \"layer3.20.conv3.weight\", \"layer3.20.bn3.running_var\", \"layer3.20.bn3.weight\", \"layer3.20.bn3.running_mean\", \"layer3.20.bn3.bias\", \"layer3.21.conv1.weight\", \"layer3.21.bn1.running_var\", \"layer3.21.bn1.weight\", \"layer3.21.bn1.running_mean\", \"layer3.21.bn1.bias\", \"layer3.21.conv2.weight\", \"layer3.21.bn2.running_var\", \"layer3.21.bn2.weight\", \"layer3.21.bn2.running_mean\", \"layer3.21.bn2.bias\", \"layer3.21.conv3.weight\", \"layer3.21.bn3.running_var\", \"layer3.21.bn3.weight\", \"layer3.21.bn3.running_mean\", \"layer3.21.bn3.bias\", \"layer3.22.conv1.weight\", \"layer3.22.bn1.running_var\", \"layer3.22.bn1.weight\", \"layer3.22.bn1.running_mean\", \"layer3.22.bn1.bias\", \"layer3.22.conv2.weight\", \"layer3.22.bn2.running_var\", \"layer3.22.bn2.weight\", \"layer3.22.bn2.running_mean\", \"layer3.22.bn2.bias\", \"layer3.22.conv3.weight\", \"layer3.22.bn3.running_var\", \"layer3.22.bn3.weight\", \"layer3.22.bn3.running_mean\", \"layer3.22.bn3.bias\", \"layer3.23.conv1.weight\", \"layer3.23.bn1.running_var\", \"layer3.23.bn1.weight\", \"layer3.23.bn1.running_mean\", \"layer3.23.bn1.bias\", \"layer3.23.conv2.weight\", \"layer3.23.bn2.running_var\", \"layer3.23.bn2.weight\", \"layer3.23.bn2.running_mean\", \"layer3.23.bn2.bias\", \"layer3.23.conv3.weight\", \"layer3.23.bn3.running_var\", \"layer3.23.bn3.weight\", \"layer3.23.bn3.running_mean\", \"layer3.23.bn3.bias\", \"layer3.24.conv1.weight\", \"layer3.24.bn1.running_var\", \"layer3.24.bn1.weight\", \"layer3.24.bn1.running_mean\", \"layer3.24.bn1.bias\", \"layer3.24.conv2.weight\", \"layer3.24.bn2.running_var\", \"layer3.24.bn2.weight\", \"layer3.24.bn2.running_mean\", \"layer3.24.bn2.bias\", \"layer3.24.conv3.weight\", \"layer3.24.bn3.running_var\", \"layer3.24.bn3.weight\", \"layer3.24.bn3.running_mean\", \"layer3.24.bn3.bias\", \"layer3.25.conv1.weight\", \"layer3.25.bn1.running_var\", \"layer3.25.bn1.weight\", \"layer3.25.bn1.running_mean\", \"layer3.25.bn1.bias\", \"layer3.25.conv2.weight\", \"layer3.25.bn2.running_var\", \"layer3.25.bn2.weight\", \"layer3.25.bn2.running_mean\", \"layer3.25.bn2.bias\", \"layer3.25.conv3.weight\", \"layer3.25.bn3.running_var\", \"layer3.25.bn3.weight\", \"layer3.25.bn3.running_mean\", \"layer3.25.bn3.bias\", \"layer3.26.conv1.weight\", \"layer3.26.bn1.running_var\", \"layer3.26.bn1.weight\", \"layer3.26.bn1.running_mean\", \"layer3.26.bn1.bias\", \"layer3.26.conv2.weight\", \"layer3.26.bn2.running_var\", \"layer3.26.bn2.weight\", \"layer3.26.bn2.running_mean\", \"layer3.26.bn2.bias\", \"layer3.26.conv3.weight\", \"layer3.26.bn3.running_var\", \"layer3.26.bn3.weight\", \"layer3.26.bn3.running_mean\", \"layer3.26.bn3.bias\", \"layer3.27.conv1.weight\", \"layer3.27.bn1.running_var\", \"layer3.27.bn1.weight\", \"layer3.27.bn1.running_mean\", \"layer3.27.bn1.bias\", \"layer3.27.conv2.weight\", \"layer3.27.bn2.running_var\", \"layer3.27.bn2.weight\", \"layer3.27.bn2.running_mean\", \"layer3.27.bn2.bias\", \"layer3.27.conv3.weight\", \"layer3.27.bn3.running_var\", \"layer3.27.bn3.weight\", \"layer3.27.bn3.running_mean\", \"layer3.27.bn3.bias\", \"layer3.28.conv1.weight\", \"layer3.28.bn1.running_var\", \"layer3.28.bn1.weight\", \"layer3.28.bn1.running_mean\", \"layer3.28.bn1.bias\", \"layer3.28.conv2.weight\", \"layer3.28.bn2.running_var\", \"layer3.28.bn2.weight\", \"layer3.28.bn2.running_mean\", \"layer3.28.bn2.bias\", \"layer3.28.conv3.weight\", \"layer3.28.bn3.running_var\", \"layer3.28.bn3.weight\", \"layer3.28.bn3.running_mean\", \"layer3.28.bn3.bias\", \"layer3.29.conv1.weight\", \"layer3.29.bn1.running_var\", \"layer3.29.bn1.weight\", \"layer3.29.bn1.running_mean\", \"layer3.29.bn1.bias\", \"layer3.29.conv2.weight\", \"layer3.29.bn2.running_var\", \"layer3.29.bn2.weight\", \"layer3.29.bn2.running_mean\", \"layer3.29.bn2.bias\", \"layer3.29.conv3.weight\", \"layer3.29.bn3.running_var\", \"layer3.29.bn3.weight\", \"layer3.29.bn3.running_mean\", \"layer3.29.bn3.bias\", \"layer3.30.conv1.weight\", \"layer3.30.bn1.running_var\", \"layer3.30.bn1.weight\", \"layer3.30.bn1.running_mean\", \"layer3.30.bn1.bias\", \"layer3.30.conv2.weight\", \"layer3.30.bn2.running_var\", \"layer3.30.bn2.weight\", \"layer3.30.bn2.running_mean\", \"layer3.30.bn2.bias\", \"layer3.30.conv3.weight\", \"layer3.30.bn3.running_var\", \"layer3.30.bn3.weight\", \"layer3.30.bn3.running_mean\", \"layer3.30.bn3.bias\", \"layer3.31.conv1.weight\", \"layer3.31.bn1.running_var\", \"layer3.31.bn1.weight\", \"layer3.31.bn1.running_mean\", \"layer3.31.bn1.bias\", \"layer3.31.conv2.weight\", \"layer3.31.bn2.running_var\", \"layer3.31.bn2.weight\", \"layer3.31.bn2.running_mean\", \"layer3.31.bn2.bias\", \"layer3.31.conv3.weight\", \"layer3.31.bn3.running_var\", \"layer3.31.bn3.weight\", \"layer3.31.bn3.running_mean\", \"layer3.31.bn3.bias\", \"layer3.32.conv1.weight\", \"layer3.32.bn1.running_var\", \"layer3.32.bn1.weight\", \"layer3.32.bn1.running_mean\", \"layer3.32.bn1.bias\", \"layer3.32.conv2.weight\", \"layer3.32.bn2.running_var\", \"layer3.32.bn2.weight\", \"layer3.32.bn2.running_mean\", \"layer3.32.bn2.bias\", \"layer3.32.conv3.weight\", \"layer3.32.bn3.running_var\", \"layer3.32.bn3.weight\", \"layer3.32.bn3.running_mean\", \"layer3.32.bn3.bias\", \"layer3.33.conv1.weight\", \"layer3.33.bn1.running_var\", \"layer3.33.bn1.weight\", \"layer3.33.bn1.running_mean\", \"layer3.33.bn1.bias\", \"layer3.33.conv2.weight\", \"layer3.33.bn2.running_var\", \"layer3.33.bn2.weight\", \"layer3.33.bn2.running_mean\", \"layer3.33.bn2.bias\", \"layer3.33.conv3.weight\", \"layer3.33.bn3.running_var\", \"layer3.33.bn3.weight\", \"layer3.33.bn3.running_mean\", \"layer3.33.bn3.bias\", \"layer3.34.conv1.weight\", \"layer3.34.bn1.running_var\", \"layer3.34.bn1.weight\", \"layer3.34.bn1.running_mean\", \"layer3.34.bn1.bias\", \"layer3.34.conv2.weight\", \"layer3.34.bn2.running_var\", \"layer3.34.bn2.weight\", \"layer3.34.bn2.running_mean\", \"layer3.34.bn2.bias\", \"layer3.34.conv3.weight\", \"layer3.34.bn3.running_var\", \"layer3.34.bn3.weight\", \"layer3.34.bn3.running_mean\", \"layer3.34.bn3.bias\", \"layer3.35.conv1.weight\", \"layer3.35.bn1.running_var\", \"layer3.35.bn1.weight\", \"layer3.35.bn1.running_mean\", \"layer3.35.bn1.bias\", \"layer3.35.conv2.weight\", \"layer3.35.bn2.running_var\", \"layer3.35.bn2.weight\", \"layer3.35.bn2.running_mean\", \"layer3.35.bn2.bias\", \"layer3.35.conv3.weight\", \"layer3.35.bn3.running_var\", \"layer3.35.bn3.weight\", \"layer3.35.bn3.running_mean\", \"layer3.35.bn3.bias\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.running_var\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.bias\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.running_var\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.bias\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.running_var\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.bias\". \n\tsize mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([20, 512]) from checkpoint, the shape in current model is torch.Size([20, 2048])."
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-958c031fde3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/model_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pth'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "%run main.py --epochs=5 --cgpu='CPU'\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea 1 : Expanding the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "%run main.py --epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2164 (0%)]\tLoss: 2.988611\n",
      "Train Epoch: 1 [640/2164 (29%)]\tLoss: 2.980144\n",
      "Train Epoch: 1 [1280/2164 (59%)]\tLoss: 3.002228\n",
      "Train Epoch: 1 [1920/2164 (88%)]\tLoss: 2.987844\n",
      "\n",
      "Validation set: Average loss: 0.0578, Accuracy: 11/103 (11%)\n",
      "Saved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 2 [0/2164 (0%)]\tLoss: 2.978810\n",
      "Train Epoch: 2 [640/2164 (29%)]\tLoss: 2.912117\n",
      "Train Epoch: 2 [1280/2164 (59%)]\tLoss: 2.784866\n",
      "Train Epoch: 2 [1920/2164 (88%)]\tLoss: 2.844584\n",
      "\n",
      "Validation set: Average loss: 0.0532, Accuracy: 14/103 (14%)\n",
      "Saved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 3 [0/2164 (0%)]\tLoss: 2.718374\n",
      "Train Epoch: 3 [640/2164 (29%)]\tLoss: 2.841185\n",
      "Train Epoch: 3 [1280/2164 (59%)]\tLoss: 2.791929\n",
      "Train Epoch: 3 [1920/2164 (88%)]\tLoss: 2.853286\n",
      "\n",
      "Validation set: Average loss: 0.0519, Accuracy: 19/103 (18%)\n",
      "Saved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 4 [0/2164 (0%)]\tLoss: 2.709709\n",
      "Train Epoch: 4 [640/2164 (29%)]\tLoss: 2.700420\n",
      "Train Epoch: 4 [1280/2164 (59%)]\tLoss: 2.692318\n",
      "Train Epoch: 4 [1920/2164 (88%)]\tLoss: 2.492675\n",
      "\n",
      "Validation set: Average loss: 0.0479, Accuracy: 18/103 (17%)\n",
      "Saved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 5 [0/2164 (0%)]\tLoss: 2.581438\n",
      "Train Epoch: 5 [640/2164 (29%)]\tLoss: 2.562902\n",
      "Train Epoch: 5 [1280/2164 (59%)]\tLoss: 2.509160\n",
      "Train Epoch: 5 [1920/2164 (88%)]\tLoss: 2.428314\n",
      "\n",
      "Validation set: Average loss: 0.0436, Accuracy: 28/103 (27%)\n",
      "Saved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 6 [0/2164 (0%)]\tLoss: 2.611264\n",
      "Train Epoch: 6 [640/2164 (29%)]\tLoss: 2.731453\n",
      "Train Epoch: 6 [1280/2164 (59%)]\tLoss: 2.163074\n",
      "Train Epoch: 6 [1920/2164 (88%)]\tLoss: 2.730052\n",
      "\n",
      "Validation set: Average loss: 0.0541, Accuracy: 17/103 (17%)\n",
      "Saved model to experiment/model_6.pth. You can run `python evaluate.py --model experiment/model_6.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 7 [0/2164 (0%)]\tLoss: 2.506897\n",
      "Train Epoch: 7 [640/2164 (29%)]\tLoss: 2.777781\n",
      "Train Epoch: 7 [1280/2164 (59%)]\tLoss: 2.610655\n",
      "Train Epoch: 7 [1920/2164 (88%)]\tLoss: 2.590674\n",
      "\n",
      "Validation set: Average loss: 0.0506, Accuracy: 16/103 (16%)\n",
      "Saved model to experiment/model_7.pth. You can run `python evaluate.py --model experiment/model_7.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 8 [0/2164 (0%)]\tLoss: 2.439919\n",
      "Train Epoch: 8 [640/2164 (29%)]\tLoss: 2.194128\n",
      "Train Epoch: 8 [1280/2164 (59%)]\tLoss: 2.424799\n",
      "Train Epoch: 8 [1920/2164 (88%)]\tLoss: 2.284643\n",
      "\n",
      "Validation set: Average loss: 0.0464, Accuracy: 23/103 (22%)\n",
      "Saved model to experiment/model_8.pth. You can run `python evaluate.py --model experiment/model_8.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 9 [0/2164 (0%)]\tLoss: 2.362431\n",
      "Train Epoch: 9 [640/2164 (29%)]\tLoss: 2.228331\n",
      "Train Epoch: 9 [1280/2164 (59%)]\tLoss: 2.317797\n",
      "Train Epoch: 9 [1920/2164 (88%)]\tLoss: 2.212495\n",
      "\n",
      "Validation set: Average loss: 0.0436, Accuracy: 25/103 (24%)\n",
      "Saved model to experiment/model_9.pth. You can run `python evaluate.py --model experiment/model_9.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 10 [0/2164 (0%)]\tLoss: 2.123047\n",
      "Train Epoch: 10 [640/2164 (29%)]\tLoss: 2.214191\n",
      "Train Epoch: 10 [1280/2164 (59%)]\tLoss: 2.290688\n",
      "Train Epoch: 10 [1920/2164 (88%)]\tLoss: 2.028552\n",
      "\n",
      "Validation set: Average loss: 0.0543, Accuracy: 21/103 (20%)\n",
      "Saved model to experiment/model_10.pth. You can run `python evaluate.py --model experiment/model_10.pth` to generate the Kaggle formatted csv file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
